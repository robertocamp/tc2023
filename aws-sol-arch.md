
## sols arch stuff
## IAM AND MFA SETUP
- navigate to IAM
- Users
- Select User
- "Security Credentials"
- "Manage Console Access"
- choose "Autogenerated Password"
- Multi-Factor (MFA)
- "Assign MFA Device"
- give a name to your device and scan the QR code
- *by default a new user no permissions at all*
- `aws sts get-caller-identity`
-  `export AWS_PAGER=""`

### IAM exam tips
- securing root account with MFA
- create an Admin group and assign the appropriate permissions to that group
- create user accounts and add users to the Admin group
- policy documents are written in JSON
- new users have no permissions by default --they must be either added to a group where they will inherit permissions or have a policy document directly applied to them (not recommended)

### delegate access to the Billing Console
- https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_billing.html
- Sign in to the AWS Management Console with your root user credentials
- On the navigation bar, choose your account name, and then choose **Account**
- Next to IAM User and Role Access to Billing Information, choose Edit.
- Select the **Activate IAM Access** check box to activate access to the Billing and Cost Management console pages
  - *You can now use IAM policies to control which Billing pages a user can access*
- attach the full "Billling" policy (ie full Billing access) to an IAM user
- in IAM navigate to Access Management|Policies
- filter the search:  "Billing"
- select the radio button on the "Billing" policy, then **Actions|Attach**
- select the user you wish to attach the policy to
- exit (save) and exit from the Root user console and login as the target IAM user, then navigate to Billing and perform some administrative task (add a new CC or similar)
- typical best practice: add the IAM user into a group and assign the policy document to the group; the IAM user will inherit the policies from the group

### Create an EC2 Key Pair
- **note**: EC2 key pairs are NOT the same as IAM|Users|Credentials|Access Keys
Amazon EC2 uses public-key cryptography to encrypt and decrypt login information. 
Public-key cryptography uses a **public key** to encrypt a piece of data, such as a password, then the recipient uses the **private key** to decrypt the data.
The public and private keys are known as a **key pair**.

## AWS Well-Architected Labs
### 100-Inventory and Patch Management
- https://www.wellarchitectedlabs.com/operational-excellence/100_labs/100_inventory_patch_management/3_deploy_env_iaac/
#### AWS Systems Manager
- AWS Systems Manager is a collection of features that enable IT Operations
- Systems Manager requires IAM role
  + for instances that will process commands
  + for users executing commands
- SSM Agent is installed by default on
  +  Amazon Linux base AMIs dated 2017.09 and later
  + Windows Server 2016 instances
  + instances created from Windows Server 2003-2012 R2 AMIs published in November 2016 or later
- enable **Configure Default Host Management Configuration** in the *Fleet Manager* section of Systems Manager
  + *Default Host Management Configuration* will create the IAM role AWSSystemsManagerDefaultEC2InstanceManagementRole for this account*
  + it is recommended to use the default role provided by Default Host Management Configuration. It contains the minimum set of permissions necessary to manage your Amazon EC2 instances using Systems Manager 
- **verify** that the **AWSSystemsManagerDefaultEC2InstanceManagementRole** is present (check IAM Roles)
- the role should be present and have the **AmazonSSMManagedEC2InstanceDefaultPolicy** attached

## Cloud Formation: 
- https://s3.us-east-2.amazonaws.com/cf-templates-13bmyhdhra48b-us-east-2/2023-04-16T195650.022Zkmn-OE_Inventory_and_Patch_Mgmt.json.json

## REVIEW QUESTIONS
### Introduction to Cloud Computing and AWS
- *Elastic BeanStalk* takes care of the ongoing underlying deployment details for you, allowing you to focus exclusively on your code. *Lambda* will respond to trigger events by running code a single time. *Auto Scaling* will ramp up exisitng infrastructure in response to demand.  *Route 53* manages DNS and network routing. 
- *CloudFront* maintains a network of endpoints where cached version fof your application data are stored to provide quicker responses to user requests. *Route53* manages DNS and network routing. *Elastic Load Balancing* routes incoming user requests among a cluster of available servers. *AWS Glacier* provides high-latency, low-cost file storage.
- *Elastic Block Storage* provides vritual block devices (think: *storage drives*) on which you can install and run filesystems and data operations. *EBS is not normally a cost-effective option for long-term data storage*
- *AWS IAM* lets you create user accounts, groups and roles and assign them rights and permissions over specific services and resources within your AWS account. **AWS Directory Service** allows you to integrate our resources with external users and resources through third-party authentication services.  *AWS KMS* is atool for generating and managijng ecnryption keys, and *SWF* is a tool for cooordinating application tasks.  Amazon Cognito can be used to manage authentication for your application users, but not your internal admin teams.
- *AWS Dynamo DB* provides a NoSQL (**nonrelational**) database service. Both are good for workloads that can be more efficiently run without the relational schema of SQL database engines (like those in Aurora). *KMS* is a tool for generating and managing encryption keys.
- EC2 endpoints will always start with an `ec2` prefix followed by the **region** designation
- An **Availability Zone** is an isolated physical data center within an AWS Region. **AWS Regions** are geographic areas that contain multiple Availabiltiy Zones. **Note** that there can be *multiple data centers* within an Availability Zone.
- *VPCs* are virtualized network environments where you can contol the connectivity of your EC2 (and RDS etc) infrstructure. *Load Balancing* routes incoming user requests amaong a cluster of available servers, CloudFront maintains a network of endpoints where cached versions of your application data are stored to provide quicker responses to user requests, and *AWS Endpoints* are URIs that point to AWS rescoures within your account.
- The **AWS Service Level Agreement** tells you the level of service availability you can realistically expect from a particular AWS Service.  You can use this information when assessing your compliance with external standards.  The *AWS Compliance Programs* page will show you which regulatory programs can be satisfied with AWS resources, not whether a particular configuration will meet their demands.
- Unlike the *Basic* and *Developer* plans, (which allow access to a support associate or to no or one user, respectively), the *Business Plan* allows mluptole team members.
- Application Migration Service can automate the testing and transfer of AWS-bound migrations of your non-cloud application servers. *Migrations Hub* is a high-level tool for coordinating migrations. *Application Discovery Service* takes an inventory of your infrastructure but doesnt migrate anything itself.
### EC2
- Many 3rd party companies maintain official and supported AMIs running their software on the AWS Marketplace. *Community AMIs* are not always official official and supported versions. When deploying multiple EC2 instances of a similar function, it is better to bootstrap them with configuration than to configure the software manually each time. The site-to-site VPN tool does not use OpenVPN
- The VM Import/Export tool handles the secure and reliable transfer of a virtual machine between a local datacenter and your AWS account. **A successfully imported VM will appear among the private AMIs in the region you selected.**  *Direct S3 uploads and SSH tunneling are not associated with VM Import/Export*
- AMIs are specific to a single AWS region and cannot be deployed into any other region. 
- in EC2, only *decicated host tenancy* offers full isolation; *shared tenancy instances* will often share hardware with operations belonging to other organisations. *Dedicated instance tenancy* instnaces may be hosted on the same physical server as other instnaces within your account
- *Reserve instances* will give you the best price for instances you know will be running 24/7, whereas *on-demand instances* make the most sense for worloads that will run at unpredicatable times but cant' be shut down until they re no longer needed. *Load-balancing* controls trafffic routeing, and on its own, has not impact on hour ability to meet the changing demand.
- *spot market* instances can be shut down with only a minimal (two-minute) warning, so they're not recommended for workloads that require reliably predicatable service. Even if your AMI can be relaunched, the interrupted workload will still be lost. Static S3 wbsites dont run on EC2 infrastructure.
- You can edit or even add or remove Security Groups from running instances and the changes wiill take effect instnactlly . Similarly, you can associate or release an elastic IP address to/from a running instance.  You can change an instance type as long as you shut down the instance first. But **the AMI cannot be chnaged**; youll need to creae an entirely new instance. 
- **Provisioned-IOPS SSD** volumes are currently the only type that comes close to 20,000 IOPS. In fact, under the right circumtstances, they cand delvier up to 256k IOPS.
- In order to create a new image from an existing EC2 instance, create a snapshot of the EBS root vovlume you need, use it to create an image, and select your new AMI from your private collection, and use it for your new launch configiuration.  
- *instance store volumes* are physically attached to the host server and add nothing to an instance's cost. The data on an instance store volume is ephemeral and will be lost as soon as the instance is shut down. There is no way to set termination protection for instance volumes because they're dependent on the life cycle of the host instance
- by default, EC2 uses the standard address blocks for subnets, so all private addresses will fail within the RFC1918 standards:
  + 10.0.0.0--10.255.255.255
  + 172.16.0.0--172.31.255.255
  + 192.168.0.0--192.168.255.255
- *ports* and *source IP address* are considered by security group rules; SG rules do not take packet size into consideration. Since a Security Group is directly associated with specific objects, there is no need to reference the target address
- IAM roles define how resources access other resources; users cannot authenticate as an instance role, not can a role be associated with an instance's internal proceses
- *NAT instances* and *NAT gateways* are are AWS tools for safelly routing traffic between private and public subnets and from there, out to the Internet. An *Internet Gateway* connects a VPC with the Internet, and a virtual private gateway connects a VPC with a remote site over a secure VPN.
- **The client computer in an encrypted operation must always use the private key to authenticate**. For EC2 instances using Windows, you retrieve the password you'll use for th GUI login using your private key.
- *Placement groups*  allow you to specify where your EC2 instances will live. *Load Balancing* directs external user requests between multiple EC2 instances. **Systems Manager** provides tools for monitoring and managing your resources. **Fargate** is an interface for administering Docker containers on Amazon ECS.
- *Lambda*  can be used to trigger an application based on reaction to network events. *AWS Elastic Beanstalk* launches and manages infrastructure for your application that will remain running until you manually stop it. *ECS* manages Docker containers but doesnt necessarilly stop them when a task is done; *Auto Scaling* can *add* instances to an already running deployment to meet demand.
- *AWS VM Import/Export* can quickly copy a VM from your private infrastructure to AWS. *S3 Buckets* are used to store an image, but they're not directly involved in the import operation. *AWS Snowball* is a physical high-capacity storage device that AWS shipts to your office for you to load data and ship back.  *Direct Connect* uses Amazon partner providers to build a high-speed connection between your data center and your AWS VPC.
- You can modify a *launch tempate* by configuring a new version of it; however, if the Auto Scaling group was created using a *Launch Configuration*. **You cannot modify a launch configuration**. *Auto Scaling doesn't use Cloud Formation templates*
- **Scheduled Actions** can adjust the minimum and maximum group sizes and the desired capacity on a schedule, which is useful when your application has a predictable load pattern. To add more instances in proportion to the aggregate CPU utilizsation of the group, implement step scaling policies.  Target tracking policieess adjust the desired capacity of a group to keep the threshold of a given metric near a predefined value. Simple scaling policies simply add more instances when a defined CloudWatch alarm triggers, but the number of instances added is not proportional to the value of the metric.
- *automation documents* let uyou perform actions against your AWS resources, including taking EBS snapshots. Although called "automation documents", you can still manually execute them. A *command document* performs actions within a Linux or Windows instance. A *policy document* works only with State Manager and can't take an EBS snapshot. 
- *Fargate* is a service that uses either ECS or EKS infrastructure uner the hood, but actually abstracts away most of the configuration details. Therefore, Fargate is your best bet for "low code" container solutions. *EKS* and *ECS* give you far greater control over your configuration, but as a result, are more complex. EKS Distro is a way fo running K8s containers in hour own infrastructure, and if anything is the most complex option of all
- aws ec2 describe-instances --instance-ids i-0e5903c79990dad0d
### AWS Storage
- Storgage Gateway and EFS (Elastic File System) provide the required read/write access. S3 can be used to share files, but it doesnt offer low-latency --and it's eventual consistentcy won't work well with filesystems. EBS volumes can be used only for a single instnace at a time.
- in theory there is no limit to the data you can upload to a single bucket or to all the buckets in your account or to the number of times you can upload (PUT). **By default however, you are allowed only 100 S3 buckets per account.**
- An HTTP (web) request must address the *s3.amazonaws.com* domain along with the bucket and filenames, eg s3.amazonaws.com/bucketname/filename
- A prefix is the name common to the objects you want to group, and a / can be used as the delimiter. Although DNS names can have prefixes, they're not the same as prefixes in S3
- Client-side encryption occurs before an object reaches the bucket (ie before it comes to rest in the bucket); only AWS KMS-Managed Keys provide an audit trail.
- S3 server access logs don't report the source bucket's current size. They don't track API calls --that's something covered by the AWS CloudTrail
- The S3 gurantee only covers the the physical infrastructure owned by AWS; temporary service outags are related to **"availability"** and not "durability"
- S3 standard-IA data has only a 99.9% availability rate, whereas the availability of Intelligent-Tiering data will change across it's life-cycle
- The S3 Standard-IA class is guaranteed to be available 99.9% of the time
- S3 can't gurantee instant consistentcy across their infrastructure for changes to existing objects, but there are no such concerns for newly created objects
- Object versioning must be manually enabled for each object to prevent older versions of the object from being deleted
- S3 lifecycle rules can incorporate specifying objects by prefix
- S3 Glacier offers the least expensive and most highly resilient storage within the AWS ecosystem. Reduced Redundancy is no longer recommended. S3 One Zone and S3 Standard are relatively expensive.
- S3 ACLs are a legacy feature that isnt' as flexible as IAM or S3 bucket policies.  **Security Groups are not used with S3 buckets** . KMS is an encryption key management tool and isnt used for authentication.
- S3 in the context of an S3 bucket policy, **a "principal" is an entity to which bucket access is assgined**
- The *default expiry value* of a pre-signed URL is **3600 seconds (one hour)**
- The AWS Certificate Manager (when used as part of a CloudFront distribution) can apply an SSL/TLS encryption certificate to your website.  You can use Route53 to associate a DNS domain name to your site.  *EC2 instances and RDS database instances would never be used for static websites.*  You would normall not use KMS for a static website--websites are usually meant to be public and encrypting the website assets with a KMS key would make it impossible for clients to download them
- retrieving and item from Glacier Deep Archive should take *no longer than 12 hrs*
- *AWS Snowball* is a quick way to transfer very large (peta-scale) data archives to the cloud. **Direct Connect** can provide fast network connections to AWS but can be very expensive and *can take up to 90 days to install.*  *Server Migration Service* and *Storage Gateway* aren't meant for moving data at great scale.
- **AWS FSx for Windows File Server** can provide low-latency read/write access to a single set of files.  *FSx for Lustre* and *Elastic File System* are primarily designed for access from Linux filesystems. **EBS volumes can't be accessed by more than one instance at a time**
### ec2 instance pricing
- **on-demand** for "always-on" deployments that you expect to run for *less than 12 months*
- **reserved**  for 24/7 deployments of *longer than one year*
- **spot** for workloads that can withstand unexpected disruption 
  + *how spot works*
  + the idea is that you enter a maxiumum dollar-value bid for an instance type runnning in a particular region.
  + the next time an instance in that region becomes available at a per-hour reate that's equal to or below your bid, it'll be launched using the AMI and launch tenmplate you specified
## SSH FUNDAMENTALS
- SSH keys are a matching set of cryptographic keys which can be used for authentication.
- Each set contains a public and a private key
- The public key can be shared freely without concern, while the private key must be vigilantly guarded and never exposed to anyone.
- To authenticate using SSH keys, a user must have an SSH key pair on their local computer.
- It is customary to place the user's **public key** on the remote systems they wish to connect to
- When a client connects to the host, wishing to use SSH key authentication, it will inform the server of this intent and will tell the server which public key to use.
- *The server then checks its authorized_keys file for the public key, generates a random string, and encrypts it using that public key.*
- **This encrypted message can only be decrypted with the associated private key.**
- The server will send this encrypted message to the client to test whether they actually have the associated private key.
- Upon receipt of this message, the client will decrypt it using the private key and combine the random string that is revealed with a previously negotiated session ID.
- It then generates an MD5 hash of this value and transmits it back to the server. 
- The server already had the original message and the session ID, so it can compare an MD5 hash generated by those values and determine that the client must have the private key.
## CLI SETUP
- `curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"`
- `sudo installer -pkg AWSCLIV2.pkg -target /`
- debug logs are written to `/var/log/install.log`
- **note** AWS CLI can also be installed via Homebrew:  installation will be located at `/opt/homebrew/bin/aws`
- either installation will create a `~/.aws` folder
- the aws configuraiton folder will have two files:
  + ~/.aws/config
    - at a minimum this file holds your default region information
  + ~/.aws/credentials
    - at a minimum this file holds your `aws_access_key_id` and `aws_secret_access_key`
- to setup authorization run this command :  `aws configure`

## Availability Zones and Regions
- a **Region** is a location in the world with (2) or more Availability Zones
- an **Availability Zone** is one or more discrete data centers with redundant power, networking and connectivity --AVs are always separate, distinct physical entities
- **Edge Locations** are used for *caching content*, typically these are in support of AWS **content delivery network** (CDN)
- there will always be more Edge Locations than Regions
- shared responsibility model:  *can I do this myself in the AWS console?* (if the answer is "yes", you are likely responsible for this item)
### VPC
- one IG per VPC
- subnets are confined to a region
- VPC router --one per VPC
- limit of 5 VPC per Region
- each VPC has a CIDR block assigned to it
- subnets are carved from the CIDR block
- Egress Only Internet Gateway: IPv6 only
- Peering Connection: connection btw VPCs
- VPC endpoints: private connections to AWS services
- NAT instance: enables Internet access for EC2 instances in the private subnets (managed by you)
- NAT gateway: enables Internet access for ec2 intances in private subnets (managed by AWS)
- Virtual Private Gateway
- Customer Gateway: customer side of a VPN connection
- AWS Direct Connect: hi-speed, hi-bandwidth private network connection from customer to AWS
- Security Group: an "instance-level" firewall
- Network ACL:  subnet-level FW
- a VPC spans all Availability Zones within a region
- each SUBNET is always within one AZ and one VPC

#### defiing VPC cidr blocks
- CIDR blocks can be between /16 and /28
- cannot be resized
- first (4) and last IP are not available for use
- AWS recommends RF1918 address space:
  + 10.0.0.0--10.255.255.255 (10/8 prefix) your VPC must be /16 or smaller, eg 10.0.0.0/16
  + 172.16.0.0--172.31.255.255 (172.16/12 prefix) your VPC must be /16 or smaller,eg 172.31.0.0/16
  + 192.168.0.0--192.168.255.255 (192.168/16 prefix) your VPC must be /16 or smaller, eg 192.168.255.255/16
- Nat Gateways alwasy go in Public Subnets!
- AMI IDs are region specific!
 
#### subnetting example
- VPC CIDR 10.0.0.0/16
- subnets:
 + 10.0.1.0/24
 + 10.0.2.0/24
 + 10.0.3.0/24
- consider deploying application tiers per subnet
- split your HA resources across subnets in different AZs
- VPC peering requires **non-overlapping subnets**
- subnet tool: 

#### Security Groups vs Network ACLs
- Network ACLs are applied at the subnet level
  + Network ACLs are STATELESS
- Security Groups are applied at the EC2 level (network interface)
  + Security Groups are STATEFUL
  + a STATEFUL FW allows the return traffic automatically
  + Security Groups have ALLOW rules only; there is a DEFAULT DENY rule at the end of the SG

#### VPC Peering
- VPC connections usign private IPv4/IPv6 addressign w/o using the Internet
- cannot have overlapping CIDR blocks
- VPC peering does not support transitivve connections--FULL MESH topology required
- 1:12:00 CONFIGURE VPC PEERING

#### VPC endpoints
- private connections to AWS services
- "interface endpoint"
  + Elastic Network Interface (ENI) with a private IP
- "gateway endpoint"
  + needs Route Table entry 
  + needs Gateway ID

#### VPC CLI
- `aws ec2 describe-vpcs --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --vpc-id vpc-092362e0add5b1693`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=vpc-id,Values=vpc-0b3448e5b71afe93b"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=vpc-id,Values=vpc-0b3448e5b71afe93b" | jq '.Subnets | length'`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=vpc-id,Values=vpc-0b3448e5b71afe93b" --query 'Subnets[*].[SubnetId]'`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-01d0f11176c90caa9"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-01d0f11176c90caa9" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-05785617d40707d40" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-03ba3d7DBc4556cf3" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-0b7cf5e391a0ee1a7" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=-subnet-04908896d6ffb4d1e" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-095bc689aebe47af4" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-06f48c9a4c79d28df" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-06762e7ea4b5d5b4f" --query "Subnets[*].AvailabilityZone"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-0e3ea1f32ff18599c" --query "Subnets[*].AvailabilityZone"`

- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-01d0f11176c90caa9" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=vpc-id, Values=subnet-05785617d40707d40" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-03ba3d7DBc4556cf3" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-0b7cf5e391a0ee1a7" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=-subnet-04908896d6ffb4d1e" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-095bc689aebe47af4" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-06f48c9a4c79d28df" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-06762e7ea4b5d5b4f" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=subnet-id, Values=subnet-0e3ea1f32ff18599c" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-route-tables --profile organization-cloud-admin-631043943452 | jq '.RouteTables | length'`
- `aws ec2 describe-route-tables --profile organization-cloud-admin-631043943452 --filter "Name=vpc-id,Values=vpc-0b3448e5b71afe93b"`
- `aws ec2 describe-route-tables --profile organization-cloud-admin-631043943452 --filter "Name=vpc-id,Values=vpc-0b3448e5b71afe93b" | jq '.RouteTables | length'`
- `aws ec2 describe-subnets --profile organization-cloud-admin-631043943452  --filters "Name=subnet-id, Values=subnet-0e3ea1f32ff18599c" --query "Subnets[*].CidrBlock"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-631043943452 --filters "Name=vpc-id,Values=vpc-0b3448e5b71afe93b" | jq '.Subnets | length'`
- `aws ec2 describe-subnets --profile organization-cloud-admin-631043943452 --filter "Name=availability-zone,Values=us-east-2a" --filter "Name=vpc-id,Values=vpc-0b3448e5b71afe93b"`
- `aws ec2 describe-subnets --profile organization-cloud-admin-631043943452 --filters "Name=availability-zone,Values=us-east-2a" --query 'Subnets[*]'`
- `aws ec2 describe-subnets --profile organization-cloud-admin-631043943452 --filters "Name=availability-zone,Values=us-east-2a" --query 'Subnets[*].VpcId'`
[?VpcId==`vpc-0b3448e5b71afe93b`]
`aws ec2 describe-subnets --profile organization-cloud-admin-631043943452 --filters "Name=availability-zone,Values=us-east-2a" --query 'Subnets[*].[?VpcId==`vpc-0b3448e5b71afe93b`]'`
aws ec2 describe-network-interfaces --filters 'Name=vpc-id,Values=vpc-097e0759b679434DB' | grep NetworkInterfaceId




##### NAT gateways
- `aws ec2 describe-nat-gateways --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filters "Name=VpcId, Values=vpc-0b3448e5b71afe93b"`
- `aws ec2 describe-nat-gateways --profile organization-cloud-admin-<ACCNT-NUM> --region us-east-2 --filter "Name=vpc-id,Values=vpc-0b3448e5b71afe93b"`
aws ec2 describe-nat-gateways --profile organization-cloud-admin-631043943452 --filter "Name=vpc-id,Values=vpc-0b3448e5b71afe93b"

##### Internet gateways
aws ec2 describe-internet-gateways --profile organization-cloud-admin-631043943452 --filter "Name=attachment.vpc-id,Values=vpc-0b3448e5b71afe93b"
#!/bin/bash -ex
export AWS_REGION=your-region-here
export AWS_PROFILE=your-cli-access-profile-here
export AWS_DEFAULT_OUTPUT=text

# Get your user ARN
aws iam get-user --query 'User.Arn'

# Get the list of key pairs available to an account sorted alphabetically
aws ec2 describe-key-pairs \
  --query 'KeyPairs[*].[KeyName] | sort(@)'

# List account role ARNs
aws iam list-roles --query 'Roles[].Arn'

# List instance ID's by name tag using filter
aws ec2 describe-instances \
  --filter 'Name=tag:Name,Values=instance-name-here' \
  --query 'Reservations[*].Instances[*].InstanceId'

# Create a volume from a snapshot ID and get the resulting volume ID
aws ec2 create-volume \
  --snapshot-id snap-id \
  --encrypted true \
  --availability-zone az \
  --query VolumeId

# List the available set of server cert ARNs
aws iam list-server-certificates \
  --query 'ServerCertificateMetadataList[*][Arn]'

# Get the first Cloudformation stack and return a specific output key value
aws cloudformation describe-stacks \
  --query "Stacks[0].Outputs[?OutputKey=='key'].OutputValue"

# Get AMIs that are available and have a substring in their name
aws ec2 describe-images \
  --filters Name=name,Values=*-name-contains-* Name=state,Values=available \
  --query 'Images[*].[ImageId,Name] | sort(@)'

# Get available Cloudformation stacks, sort by age
aws cloudformation list-stacks \
  --query 'StackSummaries[?StackStatus==`CREATE_COMPLETE`].[CreationTime,StackName] | sort(@)'

# Get the private IPs of a set of instances based on a shared tag*
# *only useful if you're expecting the instance to have only one ENI.
aws ec2 describe-instances \
  --filter Name=tag:Name,Values=tag \
  --query 'Reservations[*].Instances[].[NetworkInterfaces[0].PrivateIpAddress]'

# List record sets
aws route53 list-resource-record-sets \
  --hosted-zone-id id \
  --query 'ResourceRecordSets[*].[Name]'

# Get the availability zones of VPC subnets
aws ec2 describe-subnets \
  --query 'Subnets[*].[VpcId,SubnetId,AvailabilityZone]'

# Get the volume ID of an instance knowing the mount point and instance ID
aws ec2 describe-volumes \
  --filters Name=attachment.instance-id,Values=instance-id \
  --query 'Volumes[*].Attachments[?Device==`/dev/sdh`].VolumeId'

# Get the userdata of an EC2 instance
aws ec2 describe-instance-attribute \
  --attribue userData \
  --instance-id instance-id \
  --query 'Userdata.Value' | base64 --decode

# Get account security groups and format the output as JSON
aws ec2 describe-security-groups \
  --query SecurityGroups[*].{ID: GroupId}

# Get the first security group ID alphabetically
aws ec2 describe-security-groups \
  --query 'SecurityGroups[*].GroupId | sort(@) | [0]'
~/.aws/credentials:

[profile-name]
aws_access_key_id = <KEYID>
aws_secret_access_key = <SECRETKEYID>
~/.aws/config:

[profile profile-name]
mfa_serial = <MFAARN>
output = text
region = ap-southeast-2
role_arn = <ROLE_ARN>
s3 =
    signature_version = s3v4
source_profile = <CREDSPROFILE>


## S3 Overview
- unlimited storage (size, objects)
- 5tb limit on individual object size
- buckets are a universal namespace
- S3 bucket URLs: https://<BUCKET-NAME>.s3.Region.amazon.com/<FILE-NAME>
- S3 website URLs: http://my-bucket.s3-website-us-east-1.amazonaws.com/
- S3 website example URL:  http://my-bucket-025336094179.s3-website-us-east-1.amazonaws.com

- **s3 is basically a key value store**  --the "files" can alternatively be referred to as "keys" , with the value being the actual object (actually the value is just a sequnce of bytes)
- when you upload a file to an S3 bucket, you will receive an HTTP200 code
- s3 data is always spread across multiple devices and multiple facilities
- s3 is highly available:  99.95% -- 99.99% (depending on tier)
- s3 is designed for "11 9s" durabiltiy 99.999999999%
- designed for frequently accessed data
- suitable for most workloads
- s3 tiered storage --different tiers for different use cases
- lifecycle management --migrate objects to a cheaper tier or delete them all together
- **s3 versioning**
  + with versioning, all versions of an object are stored and can be retrieved, including deleted objects
- s3 security
  + server-side encryption: you can set default encryption on a bucket
  + ACLs define which AWS accounts or groups are granted access and the type of access
  + you can attach S3 ACLs to individual objects within a bucket
  + bucket policies: s3 bucket policies specify what actions are allowed or denied (ie a single user is allowed to PUT but not DELETE)
  + **bucket policies are json documents and apply to the bucket as a whole**
  + S3 ACLs can be applied *per object*
  + S3 has *strong read after write consistency* which means that buckets are generally available immediately after upload
- exam tips:
  + S3 is object storage: work on an individual object level
  + S3 policy: bucket policies work on the **entire bucket**
  + upt to 5tb per ojbejct
  + S3 is not used for OS or DB
  + unlimited storage
  + websites that rely on Databases cannot be hosted on S3
  + static websites can be hosted on S3
  + "static web site" means s3 bucket + bucket permissions
    - s3 websites are "static" , never dynamic
    - s3 scales automatically with demand
### S3 website lab
1. download the files from Resources section
2. `zipinfo 1662520225874-s3website.zip`
3. create new S3 bucket and enable static website
4. document static www site location from AWS console: http://tc2023-website.s3-website-us-east-1.amazonaws.com

### S3 versioning lab
- all versions of an object are stored in S3; this includes all writes and even deletes
- versioning is considered a viable "backup" method
- once enabled, *versioning cannot be disabled* --only suspended
- versioning is often integrated with Lifecycle rules
- versioning supports MFA
- previous version of an object are not available to the public (ie cannot be used in static s3 www site --but the specifified version *can be made public*)
- versioned objects can be restored by "deleting the delete marker"
- all versions of an object are stored in S3
- versioning is a great backup tool
- once versioning is enabled, **it cannot be deleted**
- versioning supports MFA -- this can be a mitigation from accidental deletion

### Storage Class Lecture: ACG
- s3 standard
  + durabiltiy >= 3 availability zones
  + 99.99 availability
  + 99.999999999
  + designed for frequent access
  + suitable for most workloads
  + first 50TB / month = 0.23/GB
- s3 standard-infrequent access (s3 standard -IA)
  - less frequent, but rapid access
  - low per GB storage price but there is a *per-GB retrieval fee*
  - same availability/durability as standard s3
  -
- s3 one-zone-infrequent access (s3 1z IA)
  + **s3 infrequent access only uses one AZ**
  + costs less than 20% of reg s3 standard
  + great for long-lived, infrequently accessed data
- s3 intelligent tiering:  designed for use-cases that combine *frequent and infrequent* access
  + *automatically moves your data to the most cost-effective tier based on how frequently you access the object*
  + monthly fee of .0025 per 1k objects
- s3 Glacier:  
  + pay each time you access your data
  + use mainly for archiving data
  + Glacier is "cheap" storage but optimized for data that is very infrequently accessed
  + Glacier standard retrieval is immediate; other Glacier class can be 12+ hrs for retrieval
  + Glacier Deep Archive: used when data needs to be archived for 7+ years
- performance accross s3
- storage costs
- exam tips

### S3 Lifecycle Management
- automates moving your objects between the different S3 storage tiers
- Glacier is much cheaper than s3 standard
- simple example: s3-30days--->s3IA-30days--->Glacier-after90days
- can be combined with versioning for fine-grained management of stored objects

### S3 Object Lock and Glacier Lock
- WORM model: "write once, ready many"
- designed to help prevent objects from being deleted or modified for fixed amount of time, or indefinitely
- can be used to help comply with govt regulatory standards
- *governance mode* users cannot overwrite or delete an object version or alter its lock settings unless they have special permissions
- *compliance mode* a protected object cannot be overwritten or deleted by any user, including the root user of the AWS account; the *retention mode cannot be changed, and the retention period cannot be shortended*
- *retention period*:  a piece of metadata that documents when the object's retention period expires
- *legal hold*: similar to a retention period, but a legal hold doesnt have an associated retention period; *it remains in effect until removed*
- legal holds can be placed or removed by any user that has the `s3:PutObjectLegalHold` permission
- **Glacier Vault Lock**
- allows you to easily deploy and enforce compliance controls for individual S3 Glacier vaults with vault lock policy
- you can specify controls such as WORM, in a vault lock policy and lock the policy from future edits

### S3 Encryption
#### types of encryption
- ssl/TLS
- https
- encryption at rest: "server-side encryption"
  + sse-s3:  s3 service manages the keys, uses AES-256-bit enryption
  + sse-kms:  AWS key management used to manage the encryption
  + sse-c: customer-provided keys used to manage the encryption
- encryption at rest: client-side encryption; user encrypts the object then sends it to S3
- **enforcing server-side encryption:**
  - console
  - bucket policy
- uploading a file to s3 is a PUT request
- if the file is to be encrypted at upload time, the `x-amz-server-side-encryption` parameter will be included in the **request header**
  + with this option, we canuse sse-s3 (aws-managed keys) or sse-kms (aws kms-managed keys)
- to enforce server-side encryption, you can create a **bucket policy** that denies any S3 PUT request that doesn't include the *x-amz-server-side-encryption* parameter in the request header.
#### exam tips
- encryption in transit: SSL/TLS/HTTPS
- encryption at rest:
- server-side encryption
- sse-s3 (aes-256)
- sse-c (client side encryption)
- client-side encryption: you encrypt the files yourself before uploading to S3
- bucket policy:  enforce server-side encryption by requiring the `x-amz-server-side-encryption parameter in the header`

### Optimizing S3 Performance
- S3 prefixes
  + mybucketname/folder1/subfolder1/file.jpg
  + the "prefix" is the path to the file, but not including the domain string or the file name
  + S3 has low-latency: you can generally get the fist byte out of S3 within 100-200 milliseconds
  + with a single prefix, you can get 5.5k GET per second
  + performance can be enhanced by spreading the requests across different prefixes
- S3 Performance
- Limitations with KMS
  + if you are using SSE-KMS, there are built-in limits to KMS
  + uploads: KMS API has a `GenerateDataKey` in the API
  + download: KMS API has a `Decrypt`
  + KMS comes with built-in, region-specific KMS quotas; eg 5.5k, 10k, 30k
- S3 Performance: uploads
  + multi-part
  + recommended for files over 100MB
  + required for files over 5GB
  + "parallelize" uploads
- S3 Performance: downloads
  + S3 byte-range fetches
  + parallelize the downloads by specifying byte ranges
  + if there is a failure in the download, it is only for a specific byte range
- Exam tips

### Backing up Data with S3 replication
- S3 Replication
  + **versioning must be enabled on the both the source and destination buckets**
  + objects in an existing bucket are not replicated automatically
  + once replciation is turne on, all subsequent updated objects will be replicated automatically
  + a *source bucket* and a *destination bucket* are required
  + **delete markers** are not replicated by default
  + S3 replication will require an IAM role
  + *the S3 storage class can be changed at the destination*

- Console

### S3 exam tips
- S3 is a "universal service" --you cannot have the same bucket name as another bucket already in service
- S3 URL:  https://<BUCKET-NAME>.s3.<REGION>.amazonaws.comn/<FILE>   ! "<FILE>" can also be referred to as "key name"
- `https://acloudguru.s3.us-east-1.amazonaws.com/mypicture.jpg`
- successful CLI or API uploads will have a 200OK status code
- S3 buckets are private by default
- *S3 ACLs* can make *individual objects* public using object ACLs
- you can make *entire buckets* public using *bucket polices*
- S3 as www site:  typically used for *static content*
- with *versioning*,  **all versions of an object are stored in S3, including deletes**
- when versioning is turned on, a deleted file has a **delete marker** associated with it
- you can remove the file by *removing the delete marker*
- versioning supports MFA
- **S3 Lifecycle Management*
- automates moving your objects between the different storage tiers
- can be used in conjunction with versioning
- can be applied to current versions and previous versions
- *S3 Object Lock and Glacier Vault Lock*
- use **S3 object lock** to store objects using a write once read many (WORM) model
- S3 object lock can be used on individual objects or applied across the bucket as a whole
- object lock comes in two modes:  *governance mode* and *compliance mode*
- with **governance mode** users can't overwrite or delete an object version or alter its lock settings unless they have special permissions
- with **compliance mode** a protected object version can't be overwritten or deleted by any user, including the root user in your AWS account
- *S3 Glacier Vault Lock* allows you to easily deploy and enforce compliance controls for individual S3 Glacier vaults with a *vault lock policy*
- you can specify controls, such as **WORM**, in a *vault lock policy* and lock the policy from future edits. Once locked the policy can no longer by changed
- S3 encryption
- "encryption in transit": SSL/TLS/HTTPS
- "encryption at rest:  server-side encryption
- SSE-S3 (AES 256-bit) (this is the default S3 encryption)
- SSE-KMS  uses AWS KMS service to handle the encryption
- S3 performance
- S3 download peformance can be enhanced by using multiple prefixes
- SSE-KMS  has built-in, region-specific limits
- these KMS limits get excercied when doing *uploads or downloads*
- S3 replication
- S3 is no longer called "x-region replication" ; can be done in same regino
- *delete markers* are not automatically included in S3 replication

## EC2 Overview
### AWS CLI
- exam tips
- Roles are the preferred solution from a security perspective
- Roles allow you to provide access without the use of access key IDs and secret access keys
- Roles are made up of policy documents, which control the Role's permissions
- when you update the policy attached to the Role, the Role's permissions are updated immediately
- changes to Security Groups take place immediately
- you can have any number of EC2 instances within a Security Group
- you an have multiple security groups attached to EC2 instances
- all inbound traffic is blocked by default
- all outbound traffic is allowed
### EC2 MetaData
- EC2 metadata: ip addr, security groups, etc
- curl http://169.254.169.254/latest/
- user data is used for bootstrap scripts
- metadata is data about the actual instance or resource
- *metadata can be accessed via user data*
### EC2 networking
- networking options on ec2
  + ENI
   * private ipv4
   * public ipv4
   * many IPv6
   * MAC address
   * 1 or more sec groups
  + EN
  + EFA
- ENI
- "enhanced networking"
  * for high-performance networking between 10G - 100G
  * uses "SR-IOV"
  * two flavors:
    - ENA elastic network adapter (always choose this)
    - used for HPC and ML apps 
    - Intel 82599 Virtual Function Interface
- ENA vs VF
  * "elastic fabric adapater"
  * a network device that you can attache to your EC2 instance
  * can enable "os-bypass" (Linux)
- exam tips
  * know the three different network adapters available on EC2:
    - ENI "elastic network interface"
    - EN "enhanced networking"
    - EFA "elastic fabric adapter" (use for High Performance Networking or Machine Learning)

### EC2 Placement Groups
- cluster  --DOES NOT span AZs
  +  group of instances w/in a single Availability Zone
  + only certain type of EC2 instances can use a clustered placement group
  + should be homogenous instance types
- spread  -- CAN span AZs
  + a group of instances that are each placed on distinct unlerlying hardware
- partition  --CAN span AZs
  + these are like "pods" , or racks of hardware
  + each group has its own set of racks

### solving licensing issues with dedicated hosts
#### review of pricing models
* on-demand
 - pay by the hour or second, depending on the type of instance you run
* reserved
 - reserved capacity for 1-3 years
 - up to a %72 discount on the hourly charge
* spot
 - purchase unused capacity at discounted rates
 - can be up to 90% off
 - hosts can be deleted on short notice
* dedicated
 - dedicated hosts can be purchased on-deomand or reserved
 - compliance
 - licensing
 - **any question about "special licensing" circumstances, think of dedicated hosts**

### EC2 Spot Instances Deep Dive
- use-case:  stateless, fault-tolerant or flexible applications, containerized workload, hi-performance computing 
- not suited for:  web servers, DB instances, critical workloads
- to use spot instances, first determine your maximum spot price
- your instances will be *stopped or terminated* when *your spot price* exceeds the current spot price
- how are spot instances terminated when you've got an open, persistent request
#### spot fleet
- a spot fleet is a collection of spot instances (and optionally on-demand instances)
- spot fleet attempts to launch the number of spot instances and on-demand instances to meet the target capacity you specified in the Spot Fleet request
  * spot fleets will try to match the target capacity with your price restraints

#### spot instances use cases
- big data analytics
- containerized workloads
- CI/CD testing
- image and media rendering
- high-performance computing
#### spot instances NOT useful
- high performance workloads
- critical jobs
- databases

#### spot instances strategy
- capacityOptimized
- diversified
- lowestPrice
- instancePoolsToUseCount

#### exam tips
- spot instances save up to 90% of the cost of on-demand instances
- spot instances are usefule for any type of workload where you *do not* need persistent storage
- you can block spot instances from terminating using a **spot block**
- a Spot Fleet is a collection of instances and (optionally) on-Demand instances

#### VMware
- you can run VMware on AWS but you need to order it thru VMware

### EC2 Outposts
- what are Outposts?
  + outposts are AWS hardware that can bootstrap an AWS environment into your private data center
- benefits?
- family members
  + Outpost Rack
    - an entire rack of servers
    - provides AWS compute, storage, database and other services locally
    - provides the same AWS infrastructure, services and APIs in your own data center
    - this more of a "data center" solution
  + Outpost Servers
    - individual servers in 1U or 2U form factor
    - suited to small-space requirements such as retail stores, branch offices, healthcare facilities etc
    - provides local compute and networking services
  
- process
  + order
  + installation: AWS staff will come on-site to install and deploy the hardware, including power, networking and connectivity
  + launch
  + build


### EC2 exam tips
- ec2 instance pricing options
   + **on-demand**: pay by the hour or second; flexible, no long-term contracts
   + **spot**: purchase un-used capacity at a discount of up to 90%
     - prices fluctuate with supply and demand
     - useful for workloads with flexible start and end times
   + **reserved**: up to 72% discount on the hourly charge
     - great if you have known, fixed requirements
   + **dedicated**: a physical ec2 server dedicated for your use
- AWS CLI 
  +  least priviledge
  + use groups --users will inherit the permissions defined by the group
  + keys should not be shared
  + AWS CLI is setup using the `aws configure` command
  + AWS CLI can be installed on Mac, Linux, Windows or EC2 instances
- AWS IAM Roles
  + always the preferred option
  + if there is a scenario where you can use a Role over some other solution, always choose the Role-based solution
  + avoid hard-coding your credentials into the role
  + **policies control a roles permissions**
  + you can update a policy attached to a role, and it will take immediate effect
  + **you can attach and detach roles to running EC2 instnaces without having to stop or terminate these instances**
- AWS Security Groups
  + changes to Security Groups take effect immediately
  + you can have any number of EC2 instances within a security group
  + you can have multiple security groups attached to EC2 instnaces
  + all inbound traffic is blocked by default
  + all outbound traffic is allowed by default
  + **bootstrap scripts** a bootstrap script is a script that runs when the instance first runs. It passes **user data** to the EC2 instance and can be used to install applications (like web servers and databases) as well as do updates and more
- *user data* vs *metadata*
  + user data are simply bootstrap scripts
  + metadata is data about your ec2 instnaces
  + *you can use bootstrap scripts (user data) to access metadata*
- ec2 networking
  + **ENI**
    - basic networking
    - example use cases: logging,  management networks 
  + **EFA**
   - if you see a scenario question that talks about EC2 being used for HPC or ML vis-a-vis networking, chose EFA ("enhanced )
   - anywhere you need reliable, high throughput
   - for when you need to accelerate High Performance Computing and machine learning
  + **enhanced networking**
    - when you need spees between 10Gbps--100Gbps
   - also supports OS-bypass
- ec2 placement groups: **logical groupings of EC2 instances**
  + *cluster placement groups* low network latency, high network throughput
    - think: High Performance Computing
  + *spread placement groups* individual, critical EC2 instances
  + *partition placement groups* multiple ec2 instances; use-cases--HDFS, Hbase, Cassandra
  - a cluster placement group **cannot span multiple availability zones**
  - a *spread placement group* and a *partition placment group* can span multiple AZs!
  - **only certain types of instances** can be launched into placement groups
    + *compute optimized, GPU, memory optimized, storage optimized*
  - *AWS recommends homegenous instnaces within cluster placement groups*
  - you cannot merge placement groups
  - you can move exisiting instances into a placement group; instance must be stopped before migrating

- EC2 dedicated hosts
 +  an ec2 **dedicated host** is a physical server with ec2 instance capacity fully dedicated to your use case
 + *dedicated hosts allow you to use your per-socket, per-core, or per-VM software licenses*
 + use cases: Windows Server, MS SQL, SUSE Linux Enterprise Server

- EC2 spot instances
 + spot instances save up to 90% of the cost of on-demand instances
 + use for any type of workload where you don't need persistent storage
 + you can block spot instances from terminating by using **spot block**
 + a spot fleet is a collection of spot instances and optionally, on-demand instances


- EC2 lab: IAM role and instance profile
  + applications that run on an EC2 instance must inclue AWS credentials in their AWS API request
  + an **instance profile** is construct used for connecting an IAM role to an EC2 instance
  + the profile is "who am I?"
  + the role is "what can I do?"
  + instance profiles provide temporary credentials which are rotated automatically


## EBS Overview
- EBS are storage volumes that you can attach to your EC2 instances
- EBS volumes are automatically replicated within a single AZ to protect against hardware failures
- **scalability** dynamically increase capacity and change the volume type with no downtime or performance impact to your live systems
### SOLID STATE DRIVES (SSD)
- **GP2**
  + good for boot volumes and general testing and dev infrastructurre
- **GP3**
  + 3k IOPS baseline
  + ideal for apps that require **high performance at a low cost** such as MYSQL, Cassandra, virtual desktop and Hadoop analytics
  + GP3 can scale up to 16k IOPS for an additional cost
- **Provisioned IOPS**
  + *SSD (io1)*
  + up to 64k IOPS per volume
  + 50 IOPS per GiB
  + designed for I.O-intensive applications, large DB and latency-sensitive workloads
  + *SSD (io2)*
  + 500 IOPS per GiB

 ### THROUPUT OPTIMIZED HDD
 - MB/s-intensive
 - **st1**
 - 40 MB/s per TB
 - max thruput 500 MB/s per volume
 - ideal for Big Data, data warehouses, ETL, log processing
 - **cannot be a boot volume**
 - **sc1**
 - max thruput 250 MB/s per volume
 - ideal for "colder data" requiring few scans per day
 - good for applications that the lowest cost and peformance is not a huge factor
 - **cannot be a boot volume**
 #### IOPS vs Thruput
   + *IOPS*
   + eg **st1**
   + measures the number of read and write operations per second
   + important metric for quick transactions
   + ideal for low-latency apps, transactional workloads
   + required when there is a need to action reads and writes very quickly
   + *thruput*
   + measures the number of bits read or written per second
   + an important metric for large datasets, large I/O sizes, and complex queries

### exam tips
#### EBS: highly available and scalable volumes you can attach to EC2 instances
- if your use-case requires more than 16K IOPS, you will want to move up to provisioned iops, like io1 or io2
- GP2:  boot disk, general apps, 3'9s availability
- GP3: faster performance than GP2
#### provisoned IOPS: suitable for OLTP and latency-sensitive applications
  - io1: 50 IOPS/GiB
  - 64K IOPS per volume
  - io2: 500 IOPS/GiB
  - up to 64k IOPs per volume
  - 99.999% durability
- just know that if you need more than 16K IOPS per volume, you will want to move to *provionsed iops*

#### HDD (magnetic drives)
- *st1*
- suitable for Big Data, data warehouses, ETL ("extract, transform, load")
- max thruput 500/MBs per volume
- **cannot be a boot volume**
- 99.9% durablity
- *sc1*
- "cold hdd"
- less frequent access,lowest cost

### Volumes and Snapshots
- *volumes* 
 + volumes are virtual hard disks
 + an ec2 instance requires at least one volume: this is usually known as the 'root volume'

- *snapshots*
 + snapshots are *point in time* copies of the data on a volume
 + snapshots exist on S3
 + only the data that has been changed since your last snapshot are moved to S3
 + snapshots are incremental
 + the first snapshot may take longer than subsequent snapshots
 + for consistent snapshots, it is recommended to stop the instance and then take a snap
 + **if you take a snapshot of an encrypted EBS volume, the snapshot will be encrypted automaticall**
 + **you can share snapshots, but only in the region in which they are created**
 + to use snapshots in other regions, you will have to first copy them to the destination regions

 #### exam tips
 - EBS volumes will always be in the same AZ as the EC2 instance to which they are attached
 - **you can  resize EBS volumes on the fly**
   + you DO NOT need to stop the instance
   + however, *you will need to extend the filesystem in the OS so the OS can see the resized volume* 
   + you can change volume types of the fly: you can go from gp2 to io2 for example
   + you do not need to stop or restart the instance to change volume types

#### exam tips: volumes and snapshots
- **volumes exist on EBS, whereas snapshots exist on S3**
- snapshots are point-in-time copies of volumes and are *incremental in nature*
- the first snapshot will take some time to create
- **for the most consistent results with snapshots, it is best to stop the instance and detach the volume**
- you can share snapshots between AWS accounts and regions, but first you need to copy that snapshot o the target region
- you can resize EBS volumes on the fly as well as change the volume type

### EBS volumes and encryption
- EBS encryption
  + data key
  + AES 256 encryption
  + **AWS EBS encryption uses AWS KMS service customer master keys when creating encrypted volumes and snapshots**
- what happens when you encrypt
  + the data at rest is encrypted inside the volume
  + all data in flight moving between the instance and the volume is encrypted
  + all snapshots are encrypted
  + all volumes created from snapshots are encrypted
  + *Amazon has a default EBS key use for encrypting snapshots*
    + for example, *a copy of* an unencrypted snapshot can be encyrpted using the default AWS EBS key
    + you can then create an *machine image* from the encrypted EBS snapshot
- encryption explained
  + encryption and decryption are handled transparently
  + latency:  encryption has a minimal impact on latency
  + **copying an unencrypted snapshot allows encryption**
  + snapshots of encrypted volumes are *automatically encrypted*
  + *root devices can now be encrypted upon creation*
- how to encrypt exisitng volumes
  + create a snapshot of the unencrypted root device volume
  + create a copy of the snapshot and select the *encrypt* option
  + create an AMI from the encryptec snapshot
  + use that AMI to launch new encrypted instances
- exam tips
  + data at rest is encrypted inside the volume
  + all data in flight moving between the instance of the volume is encrypted
  + all snapshots are encrypted
  + all volumes created from the snapshot are encrypted

#### EC2 Hibernation
- **what is EC2 hibernation?**
  - EC2 hibernation preserves the in-memory RAM on persistent storage (EBS)
  - much faster bootup --you don't need to reload the entire OS
  - RAM must be 150GB or less
  - *instances cannot be hibernated for longer than 60 days*
- if an EC2 instance is stopped, the data is kept on the EBSand will remain on the disk until the EC2 instance is started
- if the instance is terminated, then by default the volume will also be terminated
- EC2 hibernation
  + hibernation is a "suspend-to-disk" operation
  + hibernations saves the contents from the instance memory (RAM) to your AWS EBS root volume
  + we persist the EBS root volume and any attached Amazon EBS data volumes
  + you are essentially taking what's in the RAM and saving it down to disk
- starting EC2 from hibernations
  + the Amazon EBS root volume is restored to its previous state
  + the RAM contents are reloaded
  + the processes that were previously running on the instance are resumed
  + previously attached data volumes are re-attached and the instance retains its Instance ID
  + booting from hibernation is much faster compared to cold start

### EFS Overview
- "Elastic File System" (EFS)
  + managed NFS (network file system) that can be mounted on many EC2 instances at once
  + EFS works with EC2 instances in multipe AZs
  + highly available, and scalable, but **expensive**
- use cases
  + content management
  + web servers (file server)
  
- overview
  + EFS is for LINUX systems (NFSv4)
  + uses **encryption at rest**
  + **EFS scales automatically**
  + EFS has usage-based cost --the more you use, the more you pay

- performance
  + supports Lifecycle management
  + "standard tier"
  + "infrequent access" tier
- storage tiers
- exam tips
  + NFSv4
  + paid for by usage
  + scale to petabytes
  + 1000s of concurrent NFS connections
  + data is stored across multiple AZs within a Region
  + **read-after-write consistency**
  + scenario: highly-scalable shared storage using NFS

#### FSx for Windows
- Amazon FSx for Windows a native Windows NFS file system
- easily move your Windows-based applications that require file storage to AWS
- built on Windows server, runs SMB-based file services
- use-case: Sharepoint migration
- **Amazon FSx for Lustre**
 + *a fully managed file system that is optimized for compute-intensive workloads*
 + use-cases:  HPC, ML, AI, automation
 + well-suited for hundreds of gigabytes per second of thruput, millions of IOPS and sub-millisecond latencies

- exam tips
  + EFS: when you need distributed, highly resistent storage for Linux-based instances and Linux-based applications
  + AMS FSx for Windows: when you need centralised storage for Windows-based applications, such as SharePoint, MS SQL Server, Workspaces, IIS Web Server, or any other native MS application
  + AWS FSx for Lustre: when you need high-speed, hi-capacity distributed storage; apps that do HPC (high-performance-computing), financial modelling etc
    + **FSx for Lustre can store data directly on S3**
    
### Amazon machine images: EBS vs Instance Store
- what is an AMI?
  + Amazon machine image
  + you must specify an AMI when you launch an instance
- 5 things you can base your AMI on
  + Region
  + OS
  + Architecture
  + Launch permissions
  + storage for the root device (*root device volume*)

- EBS vs Instance Store
  + all AMIs are categorized as either backed by *Amazon EBS* or *Instance Store*
- Instance Store Volumes
  + instance store volumes are sometimes called *ephemeral storage*, 
  + instance store volumes cannot be stopped; if the underlying host fails, you will lose your data
  + when the EC2 instance is deleted, the instance store volume is lost
- EBS volumes
  + EBS volumes can be stopped w/o losing data
  + you can reload (reboot) an EBS volume and not lose any data
  + default EC2 configuration is to use "delete on termination" meaning the EBS volume will be deleted when the EC2 instance is deleted; *this can be changed*
- exam tips
 + instance store volumes are "ephemeral storage"
 + EBS volumes can be stopped and reloaded w/o losing data
 + be default both kinds of root volumes are deleted upon instance termination

### AWS Backup
- backup allows you to consolidate your backups across multiple AWS services, such as EC2, EBS, EFS and Amazon FSx for Lustre, Amazon FSx for Windows File Server and AWS Storage Gateway
- AWS Backup can be used with AWS Organisations
  + central management
  + automation
  + improved compliance

- exam tips
  + consolidation: use AWS backup to backup AWS services, such as EC2, EBS, EFS, FSx and AWS Storage Gateway
  + AWS Organisations: you can use AWS Organisations in conjunction with AWS Backup to back up your different AWS services across multiple AWS accounts
  + benefits: Backup gives ou centralised contol, letting you automate your backups and define **lifecycle polices** for your data. You get better compliance, as ou can enforce your backup policies, ensure your backups are encrypted, and audit them once complete

### EBS exam tips
- **ssd volumes**: highly scalable storage volumes you can attach to an EC2 instance
  + GP2
  + GP3 (newer EBS)
  + io1  +64k IOPS per volume
  + io2  + 64k IOPS per volume
- **hdd volumes**:  "magnetic" storage
  + big data, data warehouse, ETL (extract.,transform, load)
  + 500 MB/s per volume
- **volumes and snapshots**
  + volumes exist on EBS; snapshots exist on S3
  + snapshots are point-in-time copies of a volume and are *incremental in nature*
  + the first snapshot is going to take some time to create; subsequent ones should be faster
  + for *consistent snapshots* stop the instance and detach the volume
  + you can share snapshots between AWS accounts and regions, but first you need to copy that snapshot to the target region
  + you can resize EBS volumes on the flyas well as change the volume type
- **AMIs**:  EBS vs Instance Store
  + instance store volumes are sometimes known as *ephemeral storage*
  + **you can reboot both EBS and instance store volumes and you will not lose your data**
  + instance store volumes cannot be stopped; if the underlying host fails, you will lose your data
  + both instance store and EBS volumes are deleted by default upon instance termination, however with EBS you can tell AWS to keep the root device volume
  + EBS-backed instances can be stopped; you will not lose the data on this instance if it is stopped
- **encrypted volumes**:
  + data at rest is encrypted inside the volume
  + all *data in flight* moving between the instance and the volume, is encrypted
  + **all snapshots are encrypted**
  + all volumes created from your snapshots are encrypted
  + **encrypting root device volumes**
    + create a snapshot of the *unencrypted root volume*
    + create a *copy of the snapshot* and select the **encrypt option**
    + create an AMI from the encrypted snapshot
    + use that AMI to launch new encrypted instances
  + EC2 Hibernation
    + ec2 hibernation preserves the in-memory RAM on persistent storage EBS
    + faster boot time, not loading OS
    - RAM cannot be over 150GB
    - available for On-Demand and Reserved instances
- **EFS**
- NFSv4
- data is stored across multiple AZs in a region
- supports *read-after-write* consistentcy
- can scale up to petabytes
- only pay for the storage you use (ie no pre-provisioning)
- can support 1000s of concurrent NFS connections

- **FSx vs EFS scnearios**
  + use *EFS* when you need distributed, highly resilient storage for Linux instances and Linux applications
  + use *FSx for Windows* when you need centralised storage for Windows-based applications, such as SharePoint, MicrosoftSQL Server, Workspaces,IISWebServer, or any other native MS application
  + use *Amazon FSx for Lustre* when you need high-speed, high-capacity distributed storage. This will be for applications that do high performance computing (HPC), financial modeling, etc **remember that FSx for Lustre can store data directly to S3**

-  **comparing storage options**
- s3: used for serverless storage; flat files, videos
- Glacier: used for *archiving* objects
- EFS: network file share (NFS) for Linux machines; centralised storage across multiple AZs
- FSx for Lustre: file storage for *HPC Linux environments*
- EBS volumes: *persistent storage* for EC2 instances
- instance store: ephemeral storage for EC2 instances
- FSx Windows: sharepoint; file storage for Windows; centralised storage solution across multiple AZs

- AWS Backup
  + use AWS Backup as a consolidated backup solution for services including EC2, EBS, EFS, FSx Lustre, FSx Windows File Server, AWS Storage Gateway
  + AWS Backup can also use **AWS Organisations** to back up your different AWS services across multiple AWS accounts
  + Backup gives you centralised control, automation opportunities, and ease of compliance as you can enforce  backup polices, enforce encryption and carry out audits once they are complete

## STORAGE QUIZ WITH LINKS
https://aws.amazon.com/ebs/provisioned-iops/
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html
https://repost.aws/knowledge-center/create-unencrypted-volume-kms-key
https://aws.amazon.com/fsx/lustre/
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html
**EBS volumes are not encrypted by default. Reference Documentation:**
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html

## AWS RDS: Relational Databases
- data is organized into tables
- rows are the "data items"
- columns are the "fields" in the database
### AWS RDS engines
#### benefits
- Multi-AZ
- failover capability
- automated backups
#### RDS engines
- MS SQL
- Oracle
- PostgresSQL
- MariaDB
- MySQL
- Amazon Aurora
#### RDS use cases: OLTP vs OLAP
- OLTP "online transaction processing"
   + large number of small transactions in real time
- process data from transactions in real time
- OLTP vs OLAP ("online analytical processing")
  + OLAP involves analysis of large data sets
- **RDS is generally not suitable for analyzing large amounts of data**
  + *for this use-case, use a data-warehouse tool such as Amazon RedShift*
#### multi-AZ
- multi-AZ RDS creates an **exact copy**  of your production DB in another Availability Zone
- all the AWS RDS can be single AZ or Multi-AZ
- *multi-AZ is for disaster recovery, not for improving performance*
- you CANNOT connect to the stanDBy DB when the primary database is active
- **Aurora is multi-AZ by default --it will never be a single AZ solution**

### exam tip: RDS
- RDS is best for OLTP not OLAP (use RedShift for OLAP)

### RDS Read Replicas
- what is a Read Replica?
  + its a read-only copy of your primary DB
  + the read-replica handles DB queries ("reads")
  + *Read Replicas are designed to improve RDS performance*
  + **do not confuse Read Replicas with Multi-AZ:** *Multi-AZ is for disaster recovery, not performance*
  + *read replicas are designed to compliment Multi-AZ*
    + **the main purpose of read replicas is scalability**
    + **the main purpose of Multi-AZ is availability**
  + each Read Replica has its own DNS endpoint
  + Read Replicas can be promoted to be their own databases, however *this breaks the replication*
  + **in order to deploy a Read Repllica you must have automatic backup enabled**
  - *each RDS instance can have to 5 read replicas*

#### multi-az vs read replica
- *multi-AZ* is an exact copy of your production RDS instance in another availabilty zone
- **multi-az is used for disaster recovery**
- in the event of a failure, RDS will automatically fail over to the stanDBy instance
- *read replica* is read-only copy of your primary database in the same AZ, x-AZ, or x-Region
- you would typically add a *read replica* to enhance DB performance
- read replica can take the load off your primary DB *for read-only workloads*

### Amazon Aurora
- what is Aurora
  + AWS proprietary RDS DB

- Aurora performance
  + 5x performance over MySQL, 3x performance over PostgresSQL
- **basics**
  + starts @ 10GB , scales to 128TB
  + compute resources can scale to 96 vCPU and 768 GB RAM
  + **2 copies of your data are contained in each Availability Zone**, with a minimum of 3 Availability Zones
    + *this architecture gives you six copies of your data*
- **scaling** 
  + Aurora can handle the loss of up to two copies of data without affecting *DB write availability*
  + Aurora can handle up to 3 lost copies without affecting *read availability*
  + Aurora storage is "self-healing" --data blocks are disks are continually scanned for errors and repaired automatically
- types of aurora replicas
- **aurora replicas**
  + you can currently have 15 read replicas with Aurora
- **aurora backups**
- automated backups are always enabled on AWS Aurora DB instances; *backups do not impact DB peformance*
- you can also take snapshots with Aurora
- you can share your Aurora snapshots with other AWS accounts
- **aurora serverless**
- on-demand, auto-scaling configuration for the mySQL and Postgres compatible editions of Amazon Aurora.
- an Aurora serverless DB cluster automatically starts up, shuts down and scales capacity up or down based on your application's needs
- **use case:** Aurora serverless provides relatively simple, cost-effective option for infrequent, intermittent, or unpredictable workloads
- **exam tips**
- 2 copies of data in each AZ, minimum 3 AZs = min 6 copies of data!
- you can share Aurora snapshots with other AwS accounts
- 3 types of replicas available: 
  * Aurora replicas
  * MySQL replicas
  * Postgres replicas
  * **automated failover is only available with Aurora replicas**
- *Aurora has automated backups turned on by default*

### AWS DynamoDB
- **what is DynamoDB**
  + an AWS proprietary non-relational ("NOSQL") database
  + *DynamoDB supports both document and key-value pairs*
  + consistent, single-digit milisecond latency at any scale 
- **hi-level DynamoDB**
  + data is stored on SSD storage
  + data is spread across 3 geographically distinct data centers
  + default *eventually consistent reads*
  * *strongly consistent reads* are available but not by default
- **read consistency**
- *eventually consistent* all copies of data is usually reached within a second
- *strongly consistent read* returns a result that reflects all writes that received a successful response prior to the read
- **DynamoDB Accelerator (DAX)**
- fully managed, highly available, in-memory cache
- micro-second peformace
- same API calls as DynamoDB
- **on-demand capacity**
- pay-per-request
- no minimum request
- *you pay more per-request than with provisioned capacity*
- **security**
- *encryption at rest using KMS*
- site-to-site VPN
- Direct Connect (DX)
- IAM policies and roles  --allows fine-grained access
- integrates with CloudWatch and CloudTrail
- supports VPC endpoints --allows you to connect to the DynamoDB endpoint without leaving the AWS backbone (no Internet)
- **exam tips**
- DynamoDB stores data on SSD storage
- spread across 3 geographically distinct data centers
- eventually consistent reads (default)

#### DynamoDB transactions
- ACID: "Atomic, Consistent, Isolated, Durable"
  + Atomic: *all changes to the data must be performed successfully or not at all*
  + Consistent: *data must be in a consistent state before and after the transaction*
  + Isolated: *no other process can change the data while the transaction is running*
  + Durable: *the changes made by a transaction must persist*

- **DynamoDB transactions** provide developers with atomicity, consistency, isolation, and durability
- you can build transactions when building applications that require cooridnated inserts, deletes, or updates to multiple items as part of a single logical business operation
- dynmamoDB transactions are not enabled by default
- *DynamoDB transaction use-cases*
  + processing financial transactions
  + fullfilling and managing orders
  + building multiplayer game engines
  + coordinating actions across distributed components and services
- DynamoDB read options
  + enventual consistency
  + strong consistency
  + transactional
- DynamoDB write options:
  + standard
  + transactional
- 25 items or 4 MB of data per transaction

- **exam tips**
- if you see a scenario question that mentions ACID requirements, think "DynamoDB transactions"
- DynamoDB transactions provide developers atomicity, consistency, isolation, and durability ("ACID") across 1 or more tables within a single AWS account and region
- DynamoDB transactions support "all or nothing" results 

### DynamoDB backups
- *on-demand backup and restore*
  + you can perform full backups at any time
  + zero impact on table peformance or availability
  + *consistent within seconds and retained until deleted*
  * operates within the same region as the source table
- *point-in-time recovery*
- can restore to any point in the last 35 days
- protects against accidental writes or deletes
- *accomplished via incremental backups*
- *point in time recovery is not enabled by default*
- *latest restorable time is 5 minutes in the past*

### DynamoDB streams and global tables
- **streams**
  + time-ordered sequences of item-level changes in a table
  + stored for 24 hrs
  + sequences are broken up into **shards**
  + stream records are made up of inserts, updates and deletes
  + streams can be be combined with Lambda functions to achieve somethign similar to *stored procedures* in a traditional DB
- **global tables**
- global tables are managed multi-master, multi-region replication
- it is a way of replicating DynamoDB tables from one region to another
- **use-cases:** globally distributed applications
- *global tables are based on DynamoDB streams*
- streams must be turned on to enable global tables
- replication latency is under 1 second

- **exam tips:** streams and global tables
- DynamoDB global tables gives you multi-master, multi-region replication
- based on DynamoDB streams
- mulit-region redundancy for disaster recovery or high availability
- no application rewrites
- replication latency under 1 second

### Amazon DocumentDB: operating MongoDB-compatible databases
- MongoDB: an open-source document database that allows for scalability and flexibility with your data as well as robust querying and indexing features
- **Amazon DocumentDB allows you to run MongoDB on the AWS cloud**
- it is a managed database service
- allows for ez migration of a MongoDB workload to the AWS cloud
- as a managed service, much of the manual tasks associated with running MongoDB are automated in AWS Document DB

### Amazon Cassandra
- Cassandra is a distributed database (ie runs on many machines) that uses NoSQL
- **primary use case:** big data solutions
- *Amazon Keyspaces is the AWS managed solution for Cassandra databases*
- Keyspaces allows you to run your Cassandra workloads on the AWS cloud
- Keyspaces is serverless: the service can automatically scale tables up or down in response to your applications
- if you see the work **"Keyspaces"** in a scenario question, *it is most likely referring to Amazon Keyspaces*

### Amazon Neptune
- what is a graph database?
  + data is stored just like you might sketch ideas on a whiteboard
  + *a graph database stores nodes and relationships instead of tables or documents*
  + Neptune is Amazon's graph database service
- **use-cases:**
  + build connections between identities
    - identity resolution solutions
  + build knowledge graph applications
    - help users quickly navigate highly connected datasets
  + detect fraud patterns
  + security graphs to improve IT security

### AWS Quantum Ledger Database (QLDB) for ledger databases
- what is a "ledger database"
  + *a ledger database is a database that is immutable, transparent, and has a cryptographically verfiable transaction log that is owned by one authority*
  + **you cannot update a record in a ledger database; an update adds a new record to the database**
- QLDB use cases
  + cryptocurrencies such as Bitcoin, Ethereum etc
  + shppping companies use it to track boxes, shipping containers, deliveries etc
  + pharmaceutical companies use it to track creation and distribution of drugs and to ensure no counterfeits are produced

- Amazon QLDB
  + a fully managed ledger database that provides a transparent, immutable, and cryptographically verifiable transaction log

  + Amazon QLDB example use cases
    * store financial transactions
    * reconcile supply chain systems
    * maintain a claims history

- exam tips
  + **if the scnenario is not talking about immutable databases, do not select Amazon QLDB as the answer**

### Amazon TimeStream
- time-series data
  + data points that are logged over a series of time, allowing you to track your data
 
- time-series data examples
  + eg: temperature readings from weather stations around the world
  + eg: "IoT" sensors in agriculture environment
  + eg: large website tracking 

- Amazon Timestream
  + Amazon Timestream is a fully managed database service for time-series data. You can analyze trillions of events per day up to 1000 times faster and at as little as 1/10th the cost of traditional relational databases
- exam tips

### RDS Exam Tips
- RDS database types
  + SQL Server, Oracle, MySQL, Postgres, MariaDB, Aurora
  + RDS is for OLTP workloads
  + not suitable for OLAP (use data warehousing--Redshift for this)
- Read Replicas
  + **primarily used for scaling, not disaster recovery**
  + Read Replicas require automatic scaling be enabled
  + multiple read replicas are supported: up to 5 read replicas for each DB instance
- Multi-AZ vs Read Replicas
  + **multi-AZ** is an exact copy of your production DB in another Availability Zone
  + *multi-AZ is used for disaster recovery*
  + in the event of a failure, RDS will automatically failover to the standby instance, with a multi-AZ design
  + *read replicas* is a read-only copy of your primary DB in the same availabilty zone, a differt AZ or x-Region
  + *read replicas* are used to increase or scale read performance
- Aurora 
  + 2 copies of your data in each AZ, with a minimum of 3 AZs (6 copies of your data)
  + you can share Aurora snapshots with other AWS accounts
  + 3 types of replicas available: Aurora replicas MySQL replicas, Postgres replicas
  + **automated failover is only available with Aurora replicas**
  + **Aurora has automated backups turned on by default**
  + **Aurora Serverless** provides a relatively simple, cost-effective option for infrequent, intermittent, or unpredictable workloads
- DynamoDB
  + stored on SSD storage
  + spread across 3 geographically distinct data centers
  + eventually consistent reads (default)
  + strongly consistent reads are available but not default
  + DynamoDB transactions: multiple "all or nothing" operations
  + financial transactions
  + fulfilling orders
  + 3 options for reads: 1. enventual consistency, 2. strong consistency 3. transactional
  + 2 options for writes: standard, transactional
  + 25 items or 4MB of data per write
  + **if you see any scenario question that mentions "ACID requirements" , think DynamoDB transactions**

- DynamoDB on-demand backup and restore
  + full backups at any time
  + zero impact on table performance or availability
  + consistent with seconds and retained until deleted
  + operates within same egion as the source table

- DynamoDB point-in-time Recovery (PITR)
  + protects against accidental writes or deletes
  + restore to any point in last 35 days
  + incremental backups
  + not enabled be default
  + last restore available is **5min in the past**

- DynamoDB streams and global tables
  + time-ordered sequence of item-level changes in a table
  + inserts, updates, deletes
  + stored for 24 hours
  + combine with Lambda functions for functionality like stored procedures

- Managed multi-master, multi-region replications
  + use-case: globally distributed applications
  + based on DynamoDB streams
  + multi-region redundancy for disaster recovery or high availability
  + no application re-writes
  + replication latency typically under one second
  + **if global tables isnt turning on, you need to make sure you've enabled DynamoDB streams**

- Amazon Document DB
  + MongoDB-compatable workloads
  + eg migrate a MongoDB app to AWS

- Amazon Keyspaces
  + Cassandra is Big Data clusters
  + Amazon Keyspaces is the AWS managed service for Cassandra workloadsd

- QLDB
  + used for "immutable DB" applications

- AWS Timestream
  + scneario: where to store large amounts of time-series data for analysis

## VPC
### private CIDR blocks
- 10.0.0.0 -- 10.255.255.255 (10/8 prefix)
- 172.16.0.0 -- 172.31.255.255 (172.16/12 prefix)
- 192.168.0.0 -- 192.168.255.255 (192.168/16 prefix)
- **max size for any VPC is /16**
- every account comes with a default VPC in every Region
- **all subnets in a default VPC have a route out to the Internet**
- **each EC2 instance has both a public and a private IP address**
- **one subnet is always in one availability zone**
- **you can only have one Internet gateway per VPC**
- **each VPC will have a "main" Route Table, and can then have other RTs that are not the main**
#### NAT gateways in a VPC
- NAT allows instances in a private subnet to connect out to the Internet without allowing inbound access from the Internet to those instances
- the NAT gateway is typically in the same Availability Zone as your public subnet
- NAT gateways are redundant inside the Availabilty Zone
- NAT gateways start at 5Gbps and scale to 45Gpbs
- no need to ever patch your NAT gateway -this is fully managed service from AWS
- **NAT gateways are not associated with security groups**
- **NAT gateways are automatically assigned a public IP address**
#### Security Groups vs Network ACL
- Security Groups are closer to the instances than Network ACLs
- **Security Groups are virtual firewalls for an EC2 instance**
- **with Security Groups, everythign is blocked by default!**
- **Security Groups are stateful --return traffic from the Instance is allowed via the Security Group if the inbound rule allowed the traffic to ingress**
- **Network ACLs are stateless --all traffic must be explicitly allowed!**
#### Network ACls
- a network ACL is an optional layer of security for your VPC that acts as a firewall for controlling network traffic in and out of one or more subnets
- **your default VPC automatically comes with a default network ACL that by default ALLOWS ALL inbound and outbound traffic**
- when you create a *custom ALC* , by default it **DENIES ALL** inbound and outbound traffic until you add rules
- **each subnet in your VPC must be associated with a network ACL**
- *if you do not explicitly associate your subnet with a network ACL, the subnet is automatically associated with the default network ACL *
- **if you need to block a specific IP address from your subnet, you would use a Network ACL, not a Security Group**
- **you can associate a network ACL with multiple subnets; however, a subnet can be associated with only 1 network ACL at a time**
- *whenever you associate a subnet with a network ACL, the previous ACL association is removed*
- **Network ACLs have a numbered list of rules that are evaluated in order, starting with the lowest numbered rule**
- *Network ACLs have separate inbound and outbound rules and each rule can either allow or deny traffic*
- **Network ACLs are stateles** -- traffic for an allowed flow is subject to both *inbound and outbound rules*
#### VPC endpoints
- VPC endpoints allow you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, Nat devices, VPN connection or AWS Direct Connect
- **VPC endpoints are reached via the AWS backbone network**
- instances in your VPC **do not require public IP addressing to use VPC endpoints**
- **two types of VPC endpoints**
  + **interface endpoint:** is an *elastic network interface* that serves as an entry point for traffic headed to a supported service
  + **gateway endpoint:** similar to NAT gateways, a gateway endpoint is a *virtual device that you provision*
    + **gateway endpoints support connection to S3 and DynamoDB**
- in order for a an ec2 instance to access S3, a role which has S3 permissions must be attached to the EC2 instance

#### VPC peering
- VPC peering is used to connect multiple VPCs to each other
- allows you to connect 1 VPC with another via a direct network route using priviate IP addressing
- instances behave as if they were on the same private network
- you can peer VPCs with other AWS account, as well as with other VPCs in the same account
- VPC peering is a "star configuration" **-there is no transitive VPC peering**
- you can peer VPCs between regions
- **with VPC peering you cannot have overlapping CIDR address ranges**

#### PrivateLink and VPC application sharing
- PrivateLink is the best way to expose a "service VPC" to thousands of "customer VPCs"
- PrivateLink does not use traditional VPC peering, route tables, NAT gateways or Internet gateways
- **PrivateLink requires a Network Load Balancer** on the Service VPC and an **ENI on the customer VPC**
- PrivateLink will most often come up in the context of *scaling a VPC service to connect to thousands of client VPCs*

#### VPN CloudHub
- VPN CloudHub is a "hub and spoke" model for connecting multiple sites each with its own VPN
- operates over the public Internet, but all traffic is encrypted

#### AWS Direct Connect
- an AWS managed service for connecting your on-premis network to AWS
- creates a **private connection** from your private data center to AWS
- AWS Direct Connect can in some cases reduce network costs, increase bandwidth throughput and provide a more consistent network experience than Internet-based solutions
- **two types of Direct Connect**
1. dedicated connection: a physical ethernet connection associated with a single customer
2. hosted connection:  a physical ethernet conection provisioned by an AWS Direct Connect partnet (eg ATT, Verizon)
- AWS maintains Direct Connect (DX) POPs all over the world
- **VPN vs Direct Connect**
  + VPNs provide private communication (encryption) but still traverse the *public Internet* to get the data delivered
  + Direct Connect can be a superior solution to VPN when *high throughput workloads* are involved

#### AWS Transit Gateway
- connects VPCs and on-premises networks through a central hub
- creates a simpler network topology than multiple peering arrangements
- Transit Gateway acts as a **cloud router** --each new connection is only made once
- allows for **transitive peering** between thousands of VPCs and on-premises data centers
- works in a "hub and spoke" model
- *default model is Regional*
- can be expanded across multiple Regions
- can be used across multiple AWS accounts using RAM (Resource Access Manager)
- **you can use TG route tables to limit how VPCs talk to each other**
- **works with Direct Connect as well as VPN connections**
- **supports IP multicast --multicast is not supported by any other AWS service**
- is sometimes used to simply overly complex network topologies

#### AWS 5G networks
- 5G mobile networks provide mobile devices with higher speed, lower latency, and greater capacity than 4G LTE networks
- **AWS Wavelength is an AWS managed service that embeds AWS compute and storage services within 5G networks**
- designed to provide mobile edge computing and infrastructure for developing, deploying and scaling ultra-low-latency applications

### VPC EXAM TIPS
- VPCs consist of Intenet gateways (or Virtual Private Gateways), route tables, network access control lists, subnets and security groups
- 1 subnet is always in 1 availability zone
- NAT gateways are redundant inside the Avaialability Zone
- **NAT gateways are not associated with any Security Groups**
- **a NAT gateway is automatically assigned a public IP address when it is created**
- **if you have resources in multiple Availabilty Zones and they share a NAT gateway, in the event that the NAT gateway's Availabilty Zone is down, resources in the other Availability Zone will lose their Internet access**
- to create redundancy in a multi-AZ design, create a NAT gateway in each Availabilty Zone and configure your routing to ensure resources use the NAT gateway in the same Availability Zone
- Securit Groups are stateful
- your VPC comes with a Network ACL by default --**this default Network ACL allows all outbound and inbound traffic**
- *your custom Network ACL* will deny all traffic (inbound and outbound) by default
- *each subnet in your VPC must be associated with a network ACL*
- if you do not explicity associate a subnet with a network ACL, the subnet will be associated with the default Network ACL
- Network ACLs can be used to block specific IP addresses --you would not use security groups for this
- "block hackers with Network ACLs, not Security Groups"
- Network ACLs have a numbered list of rules 
- rule evaluation is done in order from lower to the higher nubmers
- **Network ACls are stateless --all traffic must be explicity allowed for flows --inbound and outbound**
- Direct Connect directly connects your data center to AWS
- Direct Connect is used for high-throughput workloads (eg lots of network traffic)
- **VPC endpoints allow connections to AWS services wihtout leaving the AWS private network**
  + interface endpoints
  + gateway endpoints (**currently only support S3 and DynamoDB**)
- **VPC peering**
  + connects one VPC with another via a direct network route using private IP addressing
  + **you can peer VPCs with VPCs in other AWS accounts as well as with VPCs in the same account**
  + VPC peering is a hub and spoke design --there is no transitive peering
  + **you can VPC peer between Regions**

- **AWS Private Link**
  + used to peer VPCs at very large scale
  + does not use traditional VPC peering or route tables
  + does not use NAT gateways or Internet gateways
  + does require a network load balancer on the service VPC

- **Transit Gateways**
  + TGs work with Direct Connect as well as VPN connections
  + **TGs support multicast --multicast is not supported by any other AWS services**

- **AWS VPN Hub**
  + provides hub and spoke network topology for various remote locations

- **AWS Wavelength**
  + AWS Wavelength can increase application speed at the edge using mobile networks
  + AWS Wavelength is a 5G technology
### default components of a custom VPC
1. Security Group
2. main VPC route table ("default" route table)
3. main network security ACL ("default" network acl)

### AWS Route-53
- DNS is used to convert human-friendly domain names into IP addresses
- IPv4: 32-bit architecture, 4billion tot addresses
- IPv6: 128-bit architecture 340undecillion addresses
- what is meant by **top level domain** in a domain string? *it is the last word in the domain string*
- top-level-domain eg:  .gov , .gov.uk, .com.au, .edu
- top-level-domains are controlled by IANA (Internet Assigned Numbers Authority)
- IANA is basically a database of all available top-level-domains
- what is a **domain registrar**
  + a *domain registrar* is an authority that can assign domain names directly under one or more top-level domains
  +  these domains are registered with InterNIC, a service of ICANN, which enforces uniqueness of domain names across the Internet
  + a registrar is authority that can assign domain names directly under one or more *top-level-domains*
  + **AWS is a domain registrar**
- SOA Record
  + supplies the name of the server that supplied the data for the zone
  + also defines an *TTL* for the record
- NS **name server records**
  + NS Records are used by top-level domain servers to direct traffic to the content DNS servers that contain the authoritative DNS records
  + *A Record* is the fundamental type of DNS record
  + the A Record is used by a computer to translate the name of the domain to an IP address
  + *TTL* is **time to live** in seconds, for a DNS record cached on either a resolving server or a user's own local machine
  + *CNAME* **cannonical name** can resolve one domain name to another
  + *alias record* an **alias** is used to map resource record sets in your hosted zone to load balancers, CloudFront distributions, or S3 buckets that are configured as websites
  - alias records work like CNAME records in that you can map one DNS name to another
  - **an alias record can map onto a nake domain name**
- The chief **difference between a CNAME record and an ALIAS record** is not in the result—both point to another DNS record—but in how they resolve the target DNS record when queried
- AWS Route53 is **Amazon's DNS registrar service**
- AWS Route 53 allows you to register domain names, create hosted zones, and manage and create DNS records

#### aliase vs CNAME in AWS
- if you are given a scenario choice involving alias vs CNAME in AWS, *always choose an alias record of a CNAME*
#### 7 Routing Polices Available with Route 53
1. simple routing
2. weighted routing
3. latency-based routing
4. failover routing
5. geolocation routing
6. geoproximity routing
7. multivalue answer routing

#### most common DNS records
- SOA record:  "start of authority"
- CNAME record: map one domain name to another
- NS record: where is the DNS info stored
- A record: maps your domain name back to an IP address

#### simple routing in R53
- one record, multiple IP addresses
- random return value from R53

#### weighted routing in R53
- sending certain % of traffic to certain regions
- you can set health checks on individual record checks
- SNS notifications can be setup for individual health checks

#### failover routing in R53
- eg primary site in US-EAST-1, failover site in US-WEST-2
- R53 can automatically redirect traffic to the failover site

#### geolocation routing policy in R53
- geolocation routing lets you choose where your traffic will be sent based on the geographic location of your users
- this is **based on the location from where the DNS queries originate**

#### geoproxity routing in R53 with R53 Traffic Flow
- uses geographic location
- latency
- availability to route traffic
- templates can help you get started
- **geoproximity routing** lets AWS R53 route traffic to your resources based on the geographic location of your users and your resources
- you can also a **bias** to intentionally favor one area over another
- **to use geoproximity routing, you must use R53 traffic flow**
  + *geoproximity routing will not show up as a record set*

#### latency-based routing in R53
- route traffic based on lowest network latency to the end user
- scenario questions involving giving uses the best experience possible based on *low latency* should look for **latency-based routing** in the solution

#### multi-value answer routing in R53
- similar to simple routing but has health-checks baked in
- R53 will use health-checks to only send to the healthy record

### R53 Exam Tips
- alias record vs CNAME
- alias records are unique to AWS --they translate a naked domain name to resource
- R53 routing policies
  + simple routing
  if you choose the simple routing policy, you can only  have one record with multiple IP addresses
  if you specify multiple values in a record, R53 returns all values to the user in a random order

  + weighted routing
  + latency-based routing
  + failover routing
  + geolocation routing
  + geoproxity routing: to use geoproximity routing, you must use R53 Traffic Flow
  + multi-value answer routing

## AWS Elastic Load Balancing
- elastic load balancing automatically distributes incoming application traffic across multiple targets, such as EC2 instances
- ELB can function across AZs
- **three types of AWS load balancers**
  1. application load balancer
    - best suited for handling HTTP/HTTPS traffic; they **operate at Layer7 and are application aware**
  2. network load balancer
    - *operate at the network level*; layer 4 ; capable of handling millions of requests per second while maintaining ultra-low latencies
    - aka "performance load balancer"  --use these when extreme peformance is a priority
  3. classic load balancer
    - this is the AWS legacy load-balancer; you can load balance HTTP/HTTPS traffic with this LB
    - you can implement Layer-7-specific features such as X-Forwarded and sticky sessions

### Application Load Balancer
- an application load balancer functions at the application layer
- after the LB receives the request, it evaluates the listener rules in priority order to determine which rule to apply
- it then selects the target from the target group for the rule action
- when the  conditions for a rule are met, the actions are performed
- *you must define a default rule for each listener*
- target groups route requests to one or more registered targets
- protocol and port numbers are part of the rulesets
- Application Load Balancers only support HTTP/HTTPS

### Network Load Balancer
- L4 Load Balancing ; *they operate at the connection layer* 
- can handle millions of requests per second
- default rule
- TCP connection to the target port
- listener forwards request to target group
- there are "no rules" in Network Load Balancing
- target group routes traffic to the target port and protocol
- you can use a TLS listener to offload the work of encryption and decryption to your load balancer
- **if the listener protocol is TLS, you must deploy exactly one SSL server certificate on the listener**
- use case:  other use cases where you need protocols that are not supported by Application Load Balancers
- network load balancers can decrypt traffic, but you will need to install the certificate on the load balancer

### AWS Classic Load Balancers
- classic load balancers are the AWS legacy load balancers
- you cal load balance HTTP/HTTPS applications and use Layer-7 specific features, such as **X-Forwarded** and **sticky sessions**
- you can also use strict layer 4 load balancing for applications that rely purely on TCP protocol
- **X-Forwarded-For**
  + when traffic is sent from a load-balancer, the application server typically logs the IP address of the proxy or the load-balancer only
  + *to see the original request of the client, use the X-Forwarded-For request header*
- 504 Errors:  **gateway timeout**
  + if the application stops responding, the Classic Load Balancer responds with an *http 504* error
- *use the X-Forwarded-For header when you need the IP address of the orginating caller*

### AWS Load Balancing with Sticky Sessions
- Classic Load Balancers route each request independently to the registered EC2 instance with the smallest load
- *sticky sessions* allow you to bind a user's session to a specific EC2 instance
- sticky sessions can be enabled with Application Load Balancer but the traffic will be sent at the target group level, which means it could theoritically still balance to other servers 
- you may see a scenario-based question where you remove an EC2 instance from a pool, but the load-balancer continues to direct traffic to the instance **you may need to disable sticky sessions to fix a problem like this**

### Leaving the Load Balancer with Deregistration Delay
- Deregistration Delay allows Load Balancers to keep existing connections open if the EC2 instnaces are de-registered or become unhealthy
- Deregistration Delay allows Load Balancers to keep existing connections open if the EC2 instances are de-registered or become unhealthy
- you can disable deregistration delay if you want your load balancer to immediately close connections to the instances that are de-registereing or have become unhealthy

### ELB exam tips
- different load balancer types: Application, Network, Classic
  + Application Load Balancer operates at L7
  + Network Load Balancer operates at L4
  + Classic Load Balancer can operate at L4/7
- a "listener" checks for connection requests on port 80/443
- rules determine how the load balancer routes requests to its registered targets
- each rule consists of a priority, one or more actions and one or more conditions
- target groups:  each target group routes requests to one or more registered targets
- Application Load Balancers only support HTTP/HTTPS traffic
- to use an HTTPS listener, you must deploy at least one SSL/TLS certificate on your load balancer


## AWS CloudWatch
- CloudWatch is a monitoring and observability platform designed to give us insight into our AWS architecture
- What can Cloudwatch monitor?
  + system-level metrics
  + CPU , memory, etc
- AWS managed services give lots of CloudWatch metrics "out of the box"
- for *application metrics* you would typically install the CloudWatch agent on your EC2 instance
- CloudWatch alarms can alert you when something goes wrong
- **two kinds of CloudWatch metrics**
  + default: "out-of-the-box"; do not require any additional work on your part to configure
    + default metrics cannot be monitored 1m or greater intervals
  + custom: need to be provided using the CloudWatch agent installed on the host
    + custom metrics can be monitored at 10s or greater
- **note that memory utilisation is not a default CloudWatch metric**
- **EBS Storage Capacity is not a default CloudWatch metric** 
- for EC2 instances you can **stop, terminate, reboot, or recover** via CloudWatch alarms

### CloudWatch examp tips
- CloudWatch is a monitoring technology
- default metrics vs custom metrics
- there are no "default alarms"
- *AWS cannot see past the hypervisor level*
  - CloudWatch cannot see memory utilisation or hdd usage
- **the standard reporting interval for CloudWatch is 5minutes ; detailed reporting will report at 1minutes**

### CloudWatch Logs

- CloudWatch Logs is a tool that allows you to **monitor, store, and access log files from a variety of different sources**
- a **log event** is the record of what happened; it typically contains a timestamp and some data
- a **log stream** is a *collection of log events from the same source*
- a **log group** is collection of log streams; for example all Apache webserver logs (ie their streams) logs could be in a single  
- filter patterns
- CloudWatch logs insights
- **Lambda will need to stream it's logs to CloudWatch**

#### CloudWatch exam tips:
- logs should to go to CloudWatch logs, except when you dont need to process them
- if you dont need to process the logs, you can send them straight to S3
- if the exam question is about *storing* logs without *processing* them (eg we are not doing any metric analysis or alerting), the logs can go directly to S3 for archival
- CloudWatch alarms can be generated based on a filter pattern for events
- CloudWatch is a *near real time* logging engine; for certain use cases where *streaming logs* are required, Amazon Kinesis may be the better fit
- CloudWatch logs is *agent based*; it must be installed and configured on the host
- CloudWatch logs insights supports SQL


### Amazon Managed Service for Prometheus and Grafana
#### Amazon Grafana
- Amazon managed Grafana is a fully managed service for allowing secure data visualizations for instantly querying, correlating, and visualizing your operational metrics, logs and traces from different sources
- based on *workspaces* --logical Grafana servers that allow for separation of data visualizations and querying
- pricing is based on per active user, per workspace
- Amazon Grafana data sources
  + Amazon CloudWatch
  + Amazon Prometheus
  + Amazon OpenSearch
  + Amazon Timestream
- Container Metric Visualizations
  + EKS
  + ECS
- many data plugins

#### Amazon Prometheus
- serverless, Prometheus-compatible service used for securely monitoring container metrics at scale
- same open source Prometheus API
- automatic scaling from AWS based on ingestion, storage, and querying of metrics
- **availability** AWS will replicate your data across three Availability Zones in the same Region
- EKS or self-mangaged cluster
- PromQL prometheus query language
- data retention: data for 150 days in Workspace

### Monitoring Exam Tips
- what is the best tool to monitor with?
- is the metric available by default? (do I need to create a custom metric?)
- where can I actually find those logs?
- do I need to adjust my alarm threshold?
- **CloudWatch is the main tool for anything alarm-related**
- **CloudWatch vs AWS Config:** changes to resources should probably be monitored by AWS Config
- *CloudWatch standard metrics are delivered every 5 minutes*
- *detailed monitoring delivers data every one minute*
- **what serivces can integrate with CloudWatch**
  + EC2, on-premesis, RDS, Lambda, CloudTrail
- if *real time* data streaming is required, **Amazon Kinesis is the preferred solution**
- **s3 uri example** s3://cfst-3029-79da2fbae4224eb1da9d1-vpcflowlogsbucket-ww55wm4w9vws/AWSLogs/123128744691/vpcflowlogs/us-east-1/2023/05/02/



## AWS Autoscaling
- horizontal
- vertical
- **launch templates** vs **launch configurations**
-  launch template
  + all of the settings that go into setting up an EC2 instance
- launch templates vs launch configurations
  + launch templates are the AWS recommended solution
  + launch templates support versioning; *launch configurations are immutable*
  + launch templates do more than autosclaing
  + **launch configurations are only for autoscaling**

### EC2 autoscaling
- autoscaling groups
 + an autoscaling group contains a collectoin of EC2 instances that are treated as a collective group for the purposes of scaling and management

- autoscaling settings
  + settings are managed in a template
  + an autoscaling group needs to be active in *at least two regions*
  + autoscaling groups define a **minimum, maximum and desired** capacity
  + *minimum* setting is the lowest number of EC2 instances you'll ever have online
  + *maximum* is the highest number of EC2 that you'd ever deploy
  + *desired* is how many instances you want "right now"
  + autoscaling events can be sent to SNS as a notification tool
  + you CAN use spot instances in an auto-scaling group!
  + autoscaling will use the EC2 health-check by default, but can use an ELB health-check if configured
  + the autoscaling group will contain the networking information that you want to deploy with your AG
  + **configure a load balancer and use the ELB health-check!**
  + SNS can act as a notificatino tool
- autoscaling limits

### AWS load balancing: step-scaling and instance warm-up and cooldown
  + **warm-up** stops instances from being placed behind the load-balancer, getting health-checked, and being pre-maturely terminated as it is just starting up 
  + **cooldown** pauses auto-scaling for a set amount of time; helps (hopes!) to avoid runaway scaling events
    + *default cooldown for auto-scaling is 5min*
### AWS load balancing: reactive scaling vs scheduled scaling vs predictive scaling
  + reactive scaling: once the load is there, you measure it and then determine if you need more infrastructure
  + scheduled scaling: *for predictable workloads*; plan to have the infrastructure scale before the load happens
  + AWS will use ML and algorithms to combine reactive and scheduled scaling; modeling is updated every 24hrs
- exam tips
  + scale-out aggressively
  + scale-in conservatively
  + **cost saving tip:  use Reserved Instances to cover the minimum auto-scaling values**
  + CloudWatch is your #1 tool for telling you if you need more or less of something!

### Scaling AWS Relational DBs
- 4 ways to scale AWS RDS
  + *vertical scaling*: simply resizing the DB infrastructure
  + *storage scaling*: keep in mind, storage can scale up , but not down! (except for Aurora --Aurora autoscales the DB in 10Gb increments)
  + *read replicas*: creating read-only copies of your data can spread out the work load
  + Aurora serverless: offloads scaling to AWS; excels with unpredictable workloads
- **scaling vs refactoring**
  + although unrealistic in the real world, some exam questions might have the correct answer be switching a non-Relational DB, like DynamoDB --easier to scale, it's more managed AWS service
  + Read Replicas: can solve read-heavy workload problems, but they do **require supporting new endpoints**
  + DB storage scaling goes up , but it does not come down --watch for this in cost-conscious questions
  + multi-AZ is the way to go, unless is a cost sensitive/DEV environment

### Scaling AWS non-Relational DB (DynamoDB)
- **provisioned** vs **on-demand**
- provisioned
  + generally predictable workload
  + set an *upper and lower scaling bound*
  + *this is the most cost-effective model*
- on-demand
  + best for sporadic workloads
  + you pay a small amount of $ per read/write; *this is a less cost effective solution*
- DynamoDB design pattern: **avoid hot keys**

### High Availabilty and Scaling Exam Tips
- gear toward chosing answers that are "high availability
- when chosing between and vertical scaling solution and a horizontal scaling solution, *generally prefer the the horizontal scaling solution*
- *autoscaling is only for EC2 instances*
- choose solutions that spread the workload across two availability zones
- **"steady state group":** min, max, desired all set to 1
  + use-case: legacy resource where we can't have more than 1 instance online at one time
- vertical scaling vs horizontal scaling
- RDS storage scales up but does not scale down!
- horizontal scaling of RDS: read replicas **but the app needs to be updated to read from the additional read-only endpoints**
- DynamoDB scaling comes down to access patterns
  + provisioned
  + on-demand

## AWS  Decoupling Workflows
- SQS
  + Simple Queue Service
  + full managed message queueing service
  + can replace an ALB *in some use cases*
  + enables you to decouple and scale microservices, distributed systems and serverless applications
- SNS
  + SNS is the go-to tool if you want to push out notifications
  + fully managed messaging service for both application-to-application (A2A) and application-to-person (A2P) communication
- API Gateway
+ fully managed service that makes it easy for developers to create, publish, maintain, monitor and secure APIs at any scale
- **while tight coupling is simpler from an architecture perspective, it does't offer any meaning ful benefits over loose coupling**
- try to avoid direct EC2-to-EC2 calls

### SQS:  Simple Queue Service
- poll-based messaging
  
- what is SQS?
  + SQS is a messaging queue that allows **asynchronous processing of work**
  + *one resource will write a message to an SQS queue, and then another resource will retrieve that message from SQS*
- SQS settings?
  + Delivery Delay: default is 0; can be set to 15min
  + message size: 256KB max
  + encryption: messages are encrypted in transit by default; **encryption at rest can be added**
  + **SQS now provides server-side encryption (SSE) using SQS-owned encryption (SSE-SQS) by default**
  + *encryption at rest* using the default SSE-SQS is provided at no additonal charge and is supported for both Standard and FIFO SQS using HTTPS endpoints
  + message retention: **default is 4 days**; *can be set to between 1min and 14days*
- visibility timeout
- long vs short polling: **long polling IS NOT the default** ...*but long polling is often the most preferred solution*
- short polling makes a quick check for messages then tries again
- short polling makes a lot of API calls to SQS --**this costs money**
- long polling connects to the SQS queue *and then waits*
- queue depth:  
- visibility timeout:  SQS puts a lock on a message once it has been retrieved by a caller
- exam tips
  + **look for long polling solutions**
  + **messages can only live up to 14 days max**
  + long vs short polling: short polling can burn CPU and cost money (API calls)

#### AWS SQS: dead-letter queue
- what is a dead-letter queue
  +  a dead-leter queue is just another SQS queue
  + messages that fail processing can be put into a dead-letter queue (DLQ)
- exam tips
  + if the scenario mentions **problems with a message in SQS**, *immediately think about DLQ and visibility timeout*
  + a "dead letter queue" is just another SQS queue **--has a 14 day max message retention setting**
  + **a CloudWatch alarm could be setup to monitor the queue depth of your dead-letter-queue**
  +  you can create an SQS DLQ for SNS topics

#### SQS Message Ordering
- **SQS offers best effort ordering by default in the STANDARD queue**
- the **FIFO QUEUE** gurantees a "first in first out" order, and also gurantees **no duplicate messages**
- the Standard queue offers *essentially unlimited messages per second processing*
- if you see a scneario where message ordering or duplication is an issue, **look for FIFO** in the answer
- FIFO does incur a peformance hit!

### Pushed based Messaging with AWS SNS
- what is "push based" messaging?
- what is SNS?
- SNS settings
  + message size 256KB
  + DLQ support (when an SQS queue is subscribed to the SNS topic)
  + Standard or FIFO SNS
  + encryption: messages are encrypted in transit by default; you can add encryption at rest
  + a resource policy can be added to an SNS topic, similar to with S3
- *poll-based messaging* is when one service delivers messages to a queue and consumer can check the queue at whatever frequency it wants*
- *push-based messaging* is when the message is delivered to the consumer via a direct channel such as email or SMS
- SNS will proactively **deliver messages to the endpoints subscribed to it**
- an SNS topci is created and *we must detemine what is subsribed to our SNS topic*
- typical SNS topic subscribers
  + Kinesis Data Firehouse
  + SQS Lambda
  + email
  + HTTPS
  + SQS
  + SMS
  + platform application endpoint
- **the FIFO SNS queue only supports SQS as a subcription protocol**

- exam tips
  + SNS can be used to push alerts based on events
  + SNS is a *push-based notification*
  + SNS is often paired with CloudWatch to send alarms
  + *HTTP and HTTPS endpoints can be retried with SNS* **--all other endpoints cannot be retried**
    - however 


### AWS API Gateway
- what is API Gateway?
  + a fully managed service that allows you to easily publish, create, maintain, monitor and secure your API
  + API gateway allows to protect the API with a WAF ("Web Application Firewall)
  + API gateway has native integration with Lambda
  + API gateway is the preferred way to get API calls into your application environment in AWS
  + API gateway supports versioning of your API
  + API gateway can reduce the need to bake credentials into your code

### Batch Workloads with AWS Batch
- what is AWS Batch?
  + a managed service for running batch computing workloads in the AWS cloud
  + *can be done with EC2 OR Fargate*
  + can automatically scale and optimize workloads
- components of AWS Batch
  + job: a unit of work submitted to AWS batch
  + job definitions:  how your job is going to be run (a blueprint for the job resources)
  + job queue: job lives in the queue until runtime
  + compute environment:  what is used to run the job
- Fargate vs EC2 environments
  + Fargate is the recommended way of launching most batch jobs
  + AWS Fargate is a technology that you can use with Amazon ECS to run containers without having to manage servers or clusters of Amazon EC2 instances.
  + if you need a **custom AMI**, then *you must run the batch on EC2*
  + high-mem requirements workloads should be run on EC2
  + high vCPU requirements should also be run on EC2
  + GPU or Graviton:  if you need these compute types, then you'll need to run the batch on EC2
  + if you many jobs and you wish for maximum concurrency, then run the batch on EC2

- AWS Batch vs AWS Lambda
  + **Lambda has a 15min execution time limit**
  + AWS batch does not have this limitation
  + AWS Lambda has limited disk space; EFS requires functions live within a VPC
  + *Lambda is fully serverless, but it has natively limited runtimes*
  * **Batch uses Docker, so any runtime can be used**
 - Managed and Unmanaged Compute Environments
  + Managed compute environments
    + AWS manages capacity and instance types
    + compute resource specs are defined when the environment is created
    + ECS instances are going to be launched into VPC subnets
    + Default AMI is the most recently approved Amazon AMI
    + *you can also use your own AMI but must meet the general ECS requirements*
  + Unmanaged compute environments
    + you manage your own resources entirely
    + AMI must meed the Amazon ECS AMI specs
    + use-case: extremely complex or specific requirements

  - Exam tips
  + AWS batch is designed for long-running,event-driven workloads
  + Lambda has a runtime limit of 15min
  + Batch is a managed service: AWS will handle infrastructure creations and configurations
  + Batch is not storage-constrained, compared to Lambda


### Amazon MQ Overview
- message broker in the cloud
- Amazon MQ is a managed service that provides a way to migrate existing applications to the AWS Cloud
- multiple programming languages
- multiple messaging protocols
- supported messaging types: **Apache ActiveMQ** and **RabbitMQ**
- allows you to easily leverage existing apps without managing and maintaining your own system
- Amazon MQ is good fit to migrate **existing applications** to cloud-based infrastructure
- Amazon MQ **requires private networking** like VPC, Direct Connect or VPN
- *Amazon SNS and SQS are publically accessible by default*
- for **new applications**, *look at SNS and SQS*
  + simpler to use, highly scalable, and simple APIs
- **Amazon MQ has NO default AWS integrations**
- Amazon MQ comes in *single instance* or *highly available* flavors

### Coordinating Distributed Apps with AWS Step Functions
- AWS Step Functions Overview
  + serverless orchestration combining different AWS services for business applications
  + graphical console for easier application workflow view and steps visualization
  + the main components of Step Functions are **state machines** and **tasks**
- Executions
  + executions are instances where you run your workflows in order to perform your tasks
- Workflows
  + standard: *can run for an entire year*; auditable history; have **exactly one** execution
  + express: can only run for up to five minutes; used for high-event-rate workflows
- States and State Machines
  + a **state machine** is a particular workflow with differnt event-driven step
  + a **task** is a *specific state* within a workflow (state machine) representing a single unit of work
  + *each step in a workflow is considered a state*
  + **Amazon States Language** ASL
  + different states
    + pass
    + task: single unit of work
    + choice: branching logic
    + wait: 
    + succeed: 
    + fail:
    + paralell:
    + map: runs a set of steps based on elements of an input array

- Integrated AWS Services: many!

- exam tips
  + AWS Steps Functions is a serverless orchestration service meant for event-driven task executions using AWS services

### Ingesting Data from SaaS Applications with AWS Amazon AppFlow
- what is AppFlow?
  + fully managed service that allows to securely exchange data between a SAS app and the AWS cloud
  + **the primary purpose is to ingest data**
  + *this a bi-directional service*
- AppFlow
  + **flows** transfer of data between sources and destinations
  + data mapping
  + filters
  + trigger: how the app is started
  + 
- use-cases:  
  + transferring Salesforce records to Amazon Redshift
  + ingesting and analyzing SLack conversations in S3
  + migrating Zendesk and other help desk support tickets to Snowflake
  + transferring aggregate data on a scheduled basis to S3

- exam tips
  + fully managed integration service transfering data to and from SAS vendors and applications
  + bi-directional


### Decoupling Workflows Exam Tips
1. are the workloads synchronous or asynchronous?
2. what type of decoupling makes sense?
3. does the order of messages matter?
4. what type of application load are we going to see?

- **SQS can duplicate messages** *--if this is an issue, choose the FIFO queue type*
- **SQS queues are NOT bidirectional**
- **default values for visibility and message retention**
  + messages stored in SQS can persist up to 14 days
- **if message ordering is important, use SQS FIFO queues**

- proactive notifications
- CloudWatch+SNS: scenarios that talk about getting an notification from a CloudWatch alarm 
- API Gateway: a secure front-end coming into your application environment
- AWS Batch: supports long-running workflows (greater than 15min)
- *Lambda has a runtime limit of 15min*
- **AWS Batch is a longer-runtime alternative to AWS Lambda**
- Amamzon MQ: supports migration of legacy messaging platforms like **RabbitMQ** or **ActiveMQ**
- Amazon Step Functions
  + usefule in your applicaitons or APIs that have **wait periods**
  + *provides conditional checks, failure catches*

- AWS App Flow
  + managed service for ingesting data from 3rd party SAS tools
  + AwS App Flow is bi-directional

### AWS Big Data
- What is RedShift?
  + 3 v's of Big Data
    + volume
    + variety
    + velocity

- Redshift is a fully managed, petabyte scale data wareshouse service in the cloud
  + **at its core Redshift is an RDS**
  + Redshift is designed for extremely large data sets
  + use case: Business Intelligence
  + Redshift is not multi-AZ by default
  + excels at BI applications and can hold more data than a traditional RDS
- exam tips
  + don't use Redshift in place of a traditional RDS

### AWS EMR: Elastic MapReduce
- what is ETL?
  + **extract, transform, load**

- what is EMR?
  + EMR is a manged big data platform
  + is is an AWS version of open-source tooling like Spark, Hive, HBse, Flink, Hudi and Presto
  +  EMR is a fleet of EC2 instances running  open-source software desgined for ETL workloads


### AWS Streaming Data with Kinesis
- What is Kinesis?
  + kinesis allows you to ingest, process and analyze real-time streaming data
  + it is analagous to a huge data highway connected to your AWS account
- **Kinesis Data Streams**
  + realtime streaming for ingesting data
  + speed: real time/near real time
  + you are responsible for creating the consumer and scaling the stream
  + **data streams needs a consumer**
- **Kinesis Data Firehouse**
  + data transfer tool to get information to S3, Redshift, ElasticSearch or Splunk
  + speed: near real time (within 60 seconds)
  + plug and play with AWS architecture
  + **much simpler to use than data streams**
  + **Kinesis Data Firehouse builds the consumer for you**

- Kinesis Data Analytics and SQL
  + *Kinesis will not process any data for you*
  + data processing can be done using standard SQL
  + santize logs, re-format IOT etc
  + no servers
  + you pay for the amount of data passing thru the service

- Kinesis vs SQS
  + if you are looking to pair a message broker with Kinesis, and the messages need to be in real time, choose Kinesis vs SQS; **Kinesis will do the messaging in real time**
  + "near real time" requirements can probably be met by Kinesis Data Streams
  + "absolute real time" requirements should favor Kinesis Firehouse

- Exam Tips
  + kinesis vs SQS: **they are both message brokers!**
  + only kinesis is suited for "real time" applications
  + for *processing* data (eg transformation) requirements, choose Kinesis Data Analytics
  + if your requirements specify that you need to *automatically scale your data streaming*, **only Kinesis Data Firehouse does this for you**

### Amazon Athena ang GLUE
- **what is Amazon Athena**
  + Athena is an interactive query service that makes it easy to analyze data in S3 using SQL
  + this allows you to directly query data in your S3 bucket without loading it into a database
  + the data can be in a data lake or an S3 bucket
- **what is Glue?**
  + Glue is a *serverless data integration service that makes it easy to discover, prepare and combine data*
  + AWS Glue crawlers can help structure the data before analyzing it in Athena
  + AWS Glue can create *data catalogs*

- exam tips
  + if your requirements contain a scenario for a *serverless SQL solution* , Athena is your best choice
  + **Athena is the only service that allows you to directly query your data that's stored in S3**
  + **Athena is serverless SQL , Glue is serverless ETL**
  + Athen is able to work by itelf, but Glue can design a schema for your data
  + **GLue is NOT a database and Athena DOES NOT query RDS!**
   
### Visualizing Data with AWS QuickSight
- What is QuickSight?
  + Quicksight is a fully-managed BI data visualization service
  + it allows you to easily create dashboards and share themn within your company
  + Quicksight is most often associated with Business Intelligent

### Moving Transformed Data Using AWS Data Pipeline
- what is AWS Data Pipeline?
  + AWS Data pipeline is a managed Extract, Transform  and Load (ETL) service for automating movement and 
  transformation of your data
  + use-cases
    - processing data in EMR using Hadoop streaming
    - importing or exporting DynamoDB data
    - copying CSV files or data between S3 buckets
    - exporing RDS data to S3
   
- exam tips
  + Data Pipeline is a managed AWS service for ETL workflows that automates movements and transformations of your data
  + data-driven workflows create dependencies between tasks and activities
  + various data storage integrations: DynamoDB, RDS, Redshift, S3
  + easy integration with EC2 and EMR
  + can leverage SNS for any failure notifications; can use SNS for success notifications or any other event-driven workloads

### AWS Managed Streaming for Apache Kafka (Amazon MSK)
- what is Amazon MSK
  + fully managed AWS service for supporting data streaming applications that require Apache Kafka
  + *Amazon MSK provides control-plane operations--creates, updates, deletes clusters as required*
- components
  + broker nodes
  + consumer nodes
  + zookeeper nodes
  + producer, consumer, topics
  + flexible cluster operations (console, CLI, SDK)
- resiliency
- logging
- exam tips


### AWS OpenSearch
- OpenSearch is a managed service allowing you to run search and analytics engines for various use cases
- **AWS OpenSearch is the successor to Amazon Elastisearch Service**
- AWS OpenSearch is a managed analytics and visualization service
- exam tips
  + a primary use-case for OpenSearch is creating a *logging solution involving visuualization* of log file analytics or BI reports

### AWS Big Data Exam Tips
1. what kind of DB works for the given scenario?
2. how much data do we have? --know the limits and defaults of each service
  + *Redshift can hold up to 16PB of data per cluster*
3. is serverless a requirements?
4. how do we optimize costs?

- Redshift and EMR
  +  not a replacment for RDS
  + **Redshift is only going to support single AZ deployments --not hightly available by default**
  + EMR is made up of EC2 instances
- **Kinesis is the only service with a real time response**
- **SQS and Kinesis can both be message brokers (ie queues)**
  + SQS is easier and simpler, but Kinesis is faster and can store data for up to a year
- for serverless SQL data queries of data in S3, use Athena
- Gule is a serverless ETL (Extract, Transform, Load)
- QuickSight can help to build dashboard esp for non-technical users
- Data Pipeline is a managed ETL service within AWS which can integrate with EC2 (+EMR), RDS, and S3
- Amazon MSK: managed Apache Kafka service in AWS; the service handles control plane operations; customer manages the data plane


## Serverless
### Lambda
- what is Lambda?
 + serverless compute service that lets you run the code w/o provisioning or managing the underlying servers
 + supported runtimes:  programming languages
 + permissions: **if your Lambda function needs to make an AWS API call, you'll need to attach a role**
 + if your Lambda needs to talk to your private endpoints, it will need additional network configuration (VPC, subnet, Security Group) that other Lambdas do not require
 + resources: you define the amount of CPU and memory your Lambda will get
 + billing: you are billed for
  + the amount of resources your Lambda uses
  + the length of time your Lambda runs
 + Lambda is designed to be *event-driven* 
  + **a Lambda typically has a "trigger" that makes the Lambda run if that event occurs**
+ Lambda excels at running small, lightweight functions
+ **Lambda can run inside or outside a database**

- building a function

### Serverless Application Repository
- allows users to easily find, deploy, or even publish their own serverless applications
- deeply integrated into AWS Lambda service
- **AWS SAM template**: upload your application code and a manifest file
  + these are essentially Cloud Formation templates
- currently two services:  **publish** and **deploy**
- deploy: browse public apps without needing an AWS account
  + if you havd an account you can browse within the Lambda console
- you can deploy your own application or deploy the publically available ones

### container appplications
- a container is a standard unit of software that packages up code and all its dependencies, so the application runs quickly and reliably from one computing environment to another

### AWS containers:  ECS vs EKS
#### ECS
- ECS can manage up to thousands of containers at a time
- ECS will appropriately place the containers and keep them online
- role integration: ECS containers can have individual roles attached to them
- ECS integrates natively with AWS Load Balancers as they come on and offline
#### open-source Kubernetes
- lots of complexity to setup
- can run on prem or in the cloud
####  EKS: AWS-managed kubernetes

#### ECS vs EKS
- use ECS for simpler workloads, esp if they are "all in" on the AWS cloud
- use EKS for more complex workloads with external dependencies
- ECS is generally the preferred solution for containers on the exam
- containers are great for one-off or long-running applications

### AWS Fargate
- what is Fargate?
  + Fargate is a serverless compute engine for containers that works with both ECS and EKS
  + **Fargate requuires the use of either ECS or EKS**
- why should we use Fargate?
- **EC2 vs Fargate**
  + dollar-for-dollar, EC2 is probably more economical
  + long-running workloads are better-suited to EC2
  + Fargate eliminates OS access
  + Fargate cost is based on resources allocated and function running time
  + Fargate excels at short-running tasks
  + Fargate provides an isolated environment
- **Fargate vs Lambda**
  + Fargate allows a certain level of standardization (containers)
  + Lambda is more AWS-centric task
  + Lambda is great  for small, one-off use cases
  + Fargate does not have a 15 min running time requirement like Lambda
  + Lamda is perfect for applications that can be expresed as a single function
- exam tips
  + Lambda vs Fargate vs EC2
  + Lambda is for light-weight functions that run very quickly and need tight integration with AWS infrastructure
  + *Fargate is when you have containers that don't need to run all the time*
  + EC2 allows you to run your containers 24/7 and is probably the best way to control costs
  + **Fargate needs ECS or EKS as an underlying deployment platform**
  + Fargate allows for longer-running applications than Lambda
  + Lambda excels at short, simple functions



### AWS EventBridge (aka CloudWatch Events)
- What is EventBridge?
  + "EventBridge" is CloudWatch 2.0
  + *it is serverless event bus*
  + is a type of "glue" that holds your serverless application together

- Creating a Rule
  + a rule basically defines a pattern that describes the event that is happening
  + rules can be scheduled or event-driven
  + AWS-based events are API calls that happen in your application environment

- EventBridge is use to kick-off Lambda function, based on some API call that happened inside AWS
- any API call that happens inside AWS can be tracked by EventBridge and used to kick-off a Lambda function
- **a common use-case is when an AWS API call is used to trigger a Lambda function**
- *EventBridge is the fastest way to respond to things happening in your application environment*


### Amazon Elastic Container Registry (ECR)
- what is ECR?
  + AWS-managed container image registry service
  + can push OCI or Docker images
  + ECR is a private container image repository with resource-based permissions via IAM
- components
  + **a private ECR registry is provided to each AWS account**
  + ECR is a *regional service*
  + ECR requires an *authentication token* that allows you to push or pull images from your ECR registry
  + **within your ECR registry, you have repositories**
  + a *repository policy* controls all access to repos and images
- **note** AWS ECR also has a *public registry* available that is not associated with an individual AWS account
- features
  + *lifecycle policies*: define rules for cleaning up unsused images; can test rules before applying them
  + *image scanning*: can help identify software vulnerabilities
  + x-region and x-account can be configured *per-repository per region*
  + pull-through cache rules
  + Amazon ECR periodically reaches out to check current caching status
  + tag mutability: prevents tags from being overwritten
- integrations
  + on-premise containers
  + ECS/EKS 
  + **Amazon Linux containers can be used locally for your software development**

- ECS exam tips
  + container image store
  + supported formats: Docker, OCI
  + lifecycle policies: rules defining when to expire and remove unused or older images
  + image scanning: **scan on push** repository settings allow for identifying software vulnerabilities in your container images
  + image tags and tag mutability: prevent images from being overwritten
  + EKS-D: when you need to run versioned deployments of clusters outside of AWS-managed services

### Orchestrating containers outside of AWS using Amazon EKS Anywhere and Amazon ECS Anywhere
- EKS-Anywhere , based on EKS-Distro
- allows you to run EKS on premise
- full lifecycle management of your EKS clusters
- **control plane management is operated completely by the customer**
- control plane is in the the customer network (customer premise)
- ECS Anywhere
  + there is no ELB support for inbound traffic
  + "external launch" type
  + requires SSM Agent, ECS Agent, and Docker installed
  + you can create an installation script inside the ECS console
  + requires an SSM activation key

### Amazon Aurora Serverless
- what is Aurora Serverless?
  + Aurora provisioned: this is the standard Aurora RDS deploymentd
  + Aurora serverless: an on-demand and auto-scaling configuration for the Amazon Aurora database service
  + automation of monitoring workloads and adjusting capacity for databases
  + *Aurora serverless is based on demand*; capacity is adjusted automaticall (ie autoscales)
  + billing: you are charged only for the resources consumed by your clusters
  + Aurora serverless is considered a "budget friendly" service because of the auto-scaling and per-second billing features

- components
  + Aurora Capacity Units (ACU): measurements on how your clusters scale
  + set a min and max for scaling requirements
  + can be zero
  + ACUs are allowed quickly by AWS-managed "warm pools"
  + **same data resiliency as Aurora provisioned:** *six copies of data across three AZs*
  + multi-AZ deployments create highly available clusters

- exam tips
  + Aurora serverless is an on-demand, auto-scaling version of the Aurora database service
  + capacity is auto-adjusted for you
  + ACU Aurora capacity unit
  + popular exam scenarios: variable workloads, new applications, capacity planning, and DEV/TEST needs
  + **same data resiliency as the Aurora provisioned:**  *six copies of data across three AZ*

### AWS X-Ray for Application Insights
- what is AWS X-RAY?
  + APP Insights collects application data for viewing filtering and gaining insights about requests and responses
  + sounds like API monitoring?
  + you can view calls to downstream AWS resources and other micro-services, APIs or databases
  + *X-Ray receives traces from your applications*
  + multiple options: integrated services can add tracing headers, send trace data or run the X-Ray daemon

- SEGMENTS are data containing resource names, request details, and other information
- SUBSEGMENTS provide more granular timing information and details
- SERVICEGRAPH a graphical representation of interacting services in requests
- TRACE ID tracks paths of requests and traces collect all segments in a request
- TRACING HEADER is an extra HTTP header containing sampling decisions and trace ID
- tracing header is named **X-Amzn-Trace-Id**
- AWS X-RAY DAEMON: an AWS software application that runs on port 2000  
  + 
- exam tips
  + anytime you heare "application insights" you should think of AWS X-RAY
  + integrates with EC2, Lambda, API Gateway
  + important terms: Traces, Tracing Headers, Segments

### AWS AppSync
- a robust, scalable GraphQL interface for application developers
- used mainly in *front-end development*

### AWS Serverless Architecture exam tips
- exam tips
  + is the application right for containers?
  + do you actually need the servers?
  + is the application *AWS-specific?*
  + how long does the code need to run?
  + **Lambda will most likely need a role** to allow it to peform the action it wants to do
  + **what can kick-off a Lambda?**
    + S3 events
    + Kinesis
    + EventBridge
  + Lambda limitations: you can allocate up to 10GB of RAM and 15min of runtime
  + functions should be short and specific
  + any AWS API call can be a trigger to kick-off an EventBridge rule
  + *EventBridge is faster than CloudTrail, for sourcing event-driven Lambda calls*
  + *Fargate does not work by itself, you will need either Amazon ECS or Amazon EKS*

  + AWS X-Ray
    - integrates tightly with AWS Lambda and API Gateway
    - X-Ray is a tracing tool for applications running in the AWS cloud
    - X-Ray can be beneficial when troubleshooting **traces** and **downstream response times**
  + AWS AppSync:  manged GraphQL interface


## Security
- what is a DDoS attack?
  + **distributed denial of service attack**
- Layer4 attacks
  + "syn flood" ; works at the TCP (transport) layer
  + after the *"tcp handshake"* , **the application starts sending data at Layer7**
  + SYN flood: flooding SYN packets but ingonring the retun ACK from the server
- Amplification attacks
  + an attacker sends a 3rd party server a spoofed requestd
- Layer7 attacks
  + a www server receives a flood of GET or POST requests, usually from a BOT NET

### logging API Calls with CloudTrail
- what is CloudTrail?
  + CloudTrail is a logging and tracking service for AWS console and API calls
- **what can CloudTrail monitor**
  + identify which users and accounts called AWS
  + the source IP address from which the calls were made
  + when the calls occurred
  + CloudTrail has been described as "CCTV" monitoring for your CloudTrail account
  + CloudTrail logs the public API calls that a user makes from either the command line or programatically
  + CloudTrail logs to S3
- **what gets logged?**
  + *metadata around the API call*
  + *the identity of the API caller*
  + *a timestamp of the API call*
  + *request parameters*
  + *the response elemetns returned by the service*
- **what is CloudTrail used for?**
  + primarily an after-the-fact incident investigation
  + provides near-real-time intrusion detection
  + in some cases CloudTrail can be used for *industry and regulatory compliance*

### Protecting Applications with AWS Shield
- what is Shield?
  + Shield is free DDOS protection; protects all AWS customers on Elastic Load Balancing (ELB), Amazon CloudFront, and Route53
  + **Shield protects against L3 and L4 attacks only**
- Shield Advanced?
  + Shield Advanced does "always-on", flow-based monitoring of network traffic and active application monitoring to provide near real-time notification of DDoS attacks
  + **gives you 24/7 access to the AWS DDoS Response Team (DRT)** to help manage and mitigate application-layer DDoS attacks
  + **protects your AWS bill (insurance policy?)** against higher fees due to Elastic Load Balancing, Amamzon CloudFront, and Amazon Route 53 usage spikes during a DDoS attack
  + Shield Advanced costs aroud $3K per month

- exam tip
  + **if the exam scenario talks about Layer3/Layer4 attacks, think AWS shield**
  + if the exam scenario talks about *application level attacks*, thing AWS WAF

### Filtering Traffic with AWS WAF
- what is WAF?
  + **Web Application Firewall**
  + monitors HTTP/HTTPS traffic that are forwarded to Amazon CloudFront or an Application Load Balancer
  + *WAF lets you control access to your content*
  + a WAF can filter on conditions such as which IP addresses are allowed or what query string parameters need to be passed for the request to be allowed
  + **WAF typically sits inf front of the Application Load Balancer or CloudFront**
- what is Layer 7 traffic?
  + *WAF operates at Layer7*
- **WAF allows three different behaviors**
  + *allow all requests EXCEPT the ones you specify*
  + *block all requests EXCEPT the ones you specify*
  + *count the requests that match the properties you specify*


### Amazon Guard Duty
- What is GuardDuty
  + Amazon GuardDuty is a threat detection service that uses machine learning to continuouly monitor for malicious behavior
  + monitors CloudTrail logs, VPC Flow Logs and DNS logs
  + monitors for unusual API calls
  + reconnaisssance by would-be attackers
  + integrated with 3rd party tooling like CrowdStrike
  + takes 7-14 days to **setup a baseline**

### Monitoring S3 Buckets with Macie
- What is Macie?
  + uses Machine Learning and pattern matching to analyse vulnerabilities in S3
  + automated AI too for detecting PII and reaching HIPPA compliance

### Securing Operating Systems with Amazon Inspector
- What is Inspector?
  + inspects network and EC2 instances
  + it is essentiall a vulnerability scan
  + looks for common vulnerabilities
  + similar to Lacework
  + CVE/CIS Benchnmarks
  + **runs as an agent on the EC2 instance**

### Managing Encryption Keys with KMS and CloudHSM
- what is AWS KMS?
  + KMS is a managed-service that makes it easy for you to creatte and control the encryption keys used to encrypt your data
  + KMS is integrated with other AWS services --such as EBS, S3 and RDS
  + *these are customer-managed encryption keys*
- encryption keys
  + KMS provides you with centralized control over the lifecycle and permissions of your keys
  + you can create new keys whenever you wish
  + you can control who can manage keys separately from who can use them
  + **CMK** *customer master key* is a logical representation of a master key
    - the CMK included metadata, such as the key ID, creation date, description and key state
  + **the CMK also contains the key material used to encrypt and decrypt data**

- how to get started with KMS?
  - *you start using the service by requesting the creation of a CMK*
  - you control the lifecycle of the CMK as well as who can use or manage it

- key rotation
  + you can choose to have AWS KMS automatically rotate CMKs every year, provided that those keys were generated with the AWS KMS HSMs
  + key rotation is not supported for imported keys

- policies
  + *the primary way to manage access to your AWS KMS CMKs is with policies*
  + **policies are documents that describe who has access to what**
  + policies attached to an IAM identity are called *identity-based policies*
  + policies that are attached to other kinds of resources are called *resource-based policies*
  + **all KMS CMKs havea  key policy**
  + you must attach a resource-based policy to your Customer Master Keys
  + *these are called key policies*

- 3 ways to control permissions in KMS
  + use the key policy
    - the full scope of access to the CMK is defined in a single document
  + use IAM policies in combination with the key policy
    - lets you managed all the permissions for your IAM identities in IAM
  + use grants in combination with the key policy
    - enables you to allow access to the CMK in the key policy, as well as allow users to delegate their access to others


- what is AWS CloudHSM
  + **hardwware security module**
  + used to create CMKs

- 3 ways to generate a CMK
  + AWS creates the CMK for ou; key material is generated within HSMs
  + import your key material from *your own key management infrastructure* and associate it with a CMK
  + custom key store feature in AWS KMS --key material is generated in AWS CloudHSM cluster


- KMS vs CloudHSM
  + KMS: shared tenancy of underlying hardware
  + automatic key rotation
  + automatic key generation
  + cloudHSM: dedicated HSM to your
  + ful control of underlying hardware
  + no key rotation


### Storing Your Secrets in Secrets Manager
- what is Secrets Manager?
  + a service that securely stores, encrypts, and rotates your database and other secrets
  + encryption in transit and at rest using KMS
  + **automatically rotates secrets**
  + fine-grained access control using IAM poicies
  + AWS Secrets manager is not a free service, but it is highly scalable
- what can you store in Secrets Manager
  +  RDS credentials
  + credentials for any other service that uses password strings or tokens
  + eg ssh keys, API keys for external services
  + your application makes an API call to Secrets Manager to retrieve the secret programatically
  + reduces the risk of credentials being compromised
  
- exam tips
  + **if you enable rotation, Secrets Manager immediately rotates the secret once to test the configuration**

### Storing your secrets in Parameter Store
- what is Parameter Store
  + Parameter Store is a capability of AWS Systems Manager that provides secure, hierarchical storage for configuration data management and secrets management
  + Parameter Store is free
- *What are the limits of Parameter Store?*
  + limited # of parameter storeage:  10k
  + there is no key rotation
- **if you need more than 10K parameters, key rotation, or the ability to generate passwords using CloudFormation, use Secrets Manager**

### Temporarily Sharing S3 objects using PreSigned URLs or Cookies
- privacy
  + **all objects in S3 are private by default**
  + *the object owner can optionally share objects with others by creating a presigned URL, using their own security credentials, to grant time-limited permission to download the objects*
- pre-signed URL
  + you must provide your security credentials
  + you specify a bucket name
  + you speicify an object key
  + you specify an HTTP method (eg GET)
  + **pre-signed URLs are valid only for the specified duration**

  + example use-case: *if you have a video in your bucket, and both the bucket and the video are private:*
    - you can share the video with others by generating a presigned URL

- pre-signed cookie
  + used when you wish to provide access to multiple restricted files
  + *the cookie will be saved on the user's computer*
  + this will enable the user to browse the entire contents of the restricted content

### Advanced IAM Policy Documents
- Amazon Resource Names (ARNs)
  + ARN syntax: arn:partition:service:region:account_id:
- IAM Policies
  + *a policy document is a list of statements*
  + each statement matches an AWS API request
- Permission Boundaries
  + *Permission Boundaries are used to delegate administration to others*
  + they help to prevent privilege escalation or unnecessarily broad permissions
  + they control the *maximum permissions* that an IAM policy can grant
  + **use-cases for Permission Boundaries**
    - Developers creating roles for Lambda functions
    - Application owners creating roles for EC2 instances
    - admins creating ad hoc users
- Exam Tips
  +  not explicitly allowed == **implicitly denied**
  + explicy deny trumps everything else
  + a policy *must be attached* before it has any effect
  + AWS *joins* all applicable policies (ie a resource can multiple policies joined to it)
  + AWS has varioius managed policies 
  + customers can write their own policies


### AWS Certificates Manageer
- what is AWS Certificate Manager
  + AWS Certificate Manager allows you to create, manage, and deploy public and private SSL certificates for use with other AWS services
  + integrates with other services such as ELB, CloudFront and APIGateway
  + AWS Certificates Manager is is a free service --you only pay for the resources that utilise your certificates
  + AWS Certificate Manager can automate the renewal of your SSL certificate with ACM-integrated services, such as Elastic Load Balancing, CloudFront and API Gateway


### Auditing Continuously with AWS Audit Manager
- what is AWS Audit Manager?
  + Audit Manager is an automated service that produces reports specific to auditors for PCI compliance, GDPR, etc
  + the idea behind Audit Manager is a *continuous auditing service*

###   Downloading Compliance Documents with AWS Artifact
- AWS artifact is a single source you can visit to get the compliance-related information that matters to you
- what kind of reports are available?
  + Service Organization Control (SOC)
  + Payment Card Industry (PCO)
  + GDPR reports

### Authenticating Access with Amazon Cognito
- what is Amazon Cognito
  + Cognito is a service that provides authentication, authorization and user management for your web and mobile apps in a single service without the need for custom code
  + users can sign in directlly with a username and password they create or through a third party such as Facebook, Amazon, Google, or Apple
  + *Amazon Cognito is essentially an authentication engine*

- features
  + sign-up and sign-in options for your applications
  + access for guest users
  + acts as an identity broker between your application and web ID providers
  + synchronises user data across multiple devices
  + recommended for all mobile applications that call AWS services
- use-cases
  + **authentication** users can sign in using a user pool or a 3rd party identity provider such as Facebook or Google
  + Cognito itself can be the IdP (Identity Provider)
  + server-side resource access using tokens
  + users can be given access to AppSync resources with tokens received from a user or identity pool in Cognito
  + users can be given access to AppSync resources with tokens received from a user or identity pool in Cognito


- user pools and identity pools
  + **user pools** are directories of users that provide sign-up and sign-in options for your application users
  + **identity pools** allow you to give your users access to other AWS services
  + *you can use identity pools and user pools either separately or together*
- how it works broadly
- cognito sequence
- exam tips
  + **user pool** user directories that provide sign-up and sign-in options for users of your application
  + **identity pools** allows your users to access other AWS services
  + you can use identity pools and user pools separately or together

### Analyzing Root Cause Using Amazon Detective
- What is Detective?
  + AI/ML service that enables you to analyze, investigate and quickly identify the root cause of potential security issues or suspicious activities
- Detective Sources?

- exam tips
  + **do not confuse Detective with Inspector**
  + Amazon Inspector is an automated vulnerability management service that continually scans EC2 and container workloads for software vulnerabilities


### Protecting VPCs with AWS Network Firewall
- what is AWS Network Firewall?
  + AWS Network Firewall is a managed service that makes it easy to deploy physical firewall protection across your VPCs
  + *it is a physical firewall managed by AWS*

- benefits
  + works with AWS Network Firewall Manager
  + you can centrally manage security policies across existing and newly created VPCs
  + also provides an Intrusion Prevention System (IPS) that gives you active traffic flow inspection
- use caes
- exam tips

### Leveraging AWS Security Hub for Collecting Security Data
- what is Amazon Security Hub?
  + Security Hub is a "single pane of glass" application to view alerts and information from security services such as Amazon Guard Duty, Inspector, and Macie
  + *works across multiple accounts*

### Security Exam Tips
- CloudTrail provides after-the-fact incident investigation
- near real-time intrusion detection
- industry and regulatory compliance
- Cloud Trail is essentially a "CCTV" for your AWS account
  + **CloudTrail will log all API calls made in your AWS account and store these logs on S3**
  + Amazon Shield is a **Layer3/Layer4 DDOS protection**
    + *Shield Advance* is a $3k monthly service that gives access to a 24/7 DDOS response team
  + AWS WAF (web application firewll) is software tool that protects agains Layer7 attacks
  + **WAF can help prevent access to specific countries or IP addresses**
  + AWS Firewall Manager
  + AWS Guard Duty uses AI to learn what normal activity looks like in your account and then alerts you to deviations from this  norm 
  + Guard Duty uses a database from various 3rd party sources to create a list of known malicious domains
  + Guary Duty also monitors VPC flow logs, CloudTrail logs, and DNS logs
  + CloudWatch events can also be used to trigger a Lambda function to address a threat
  + Macie use AI to analyze data in S3 and helps identify PII, PHI, and financial data
  + Amazon Inspector is used to perform vulnerability scans on both EC2 instances and VPCs
  + AMS KMS is a managed service that makes it easy for you to create and control the encryption keys used to encrypt your data
  + **you start using KMS by requesting the creation of a CMK**
  + *KMS provides automatic key rotation*
  + CloudHSM is a dedicated hardware device for encrypting data
  + *CloudHSM does not provide automatic key rotation*
  + AWS Secrets Manager is a managed key store service with an API and automatic key rotation
  + **when enabled, Secrets Manager will rotate credentials immediately**

  + Parameter Store vs Secrets Manager
  + Pre-Signed URLs
  + advanced IAM policies
  + AWS Certificates Manager: most often used with ELB, CloudFront , APIGateway
  + AWS Audit is a tool to "automate your auditing" and can be used to achieve HIPPA or GDPR compliance

  + AWS Artifact is used to retrieve documents associated with AWS Audit
  + AWS Cognito
    - **user pools** user directories that provide sign-in and sign-up options for users of your applications
    - **identity pools** allow users access to other AWS services
    - you can use identity pools and user pools separately or together
  + AWS Detective vs AWS Inspector
    + Inspector is an automated vulnerability detection tool
    + Detective is an AI-enabled tool for analyzing **root cause** of an event
  + AWS Network Firewall is a hardware-based firewall that sits in front of your VPC
    - *AWS manages the hardware*
  + AWS Security Hub
    - "single pane of glass" to view all alerting from security services across multiple AWS accounts

### AWS Systems Manager
- what is Systems Manager
  + Systems Manager is suite of tools that lets you view, control and automate your AWS architecture and your on-premise resources
  + Systems Manager is provided at no cost by AWS
  + Systems Manager is an instance configuration tool, that allows you to peform typicall 'sys-admin' tasks on your server
  
- components
  +  automation documents (aka "run books")
  + *Systems Manager is an agent-based tool that needs to be installed on your EC2 instances*
  + Patch manager --manages your application verions
  + Parameter store --securely stores your secret values
  + *an EC2 instance needs a role in order to communicate with the Systems Manager service*
  + Session Manager --replaces traditional SSH key access to your systems

### Automation Exam Tips
1. can you automate it?
2. what kind of automation works in this scenario?
3. is the automation repeatable?
4. is the solution x-region or x-account compatible?

- prefer "immutable architecture" --the solution should be just as easy to revert as to apply again 
- CloudFormation: parameter store vs mapping sections
- CloudFront defaults to HTTPS connecctions with the ability to add a custom SSL certificate


## Caching
- AWS caching solutions
  + CloudFront
  + Elasticache
  + DAX
  + Global Accelerator

### CloudFront
- what is CloudFront?
  + CloudFront is an AWS Content Delivery Network (CDN) that securely delivers data, videos, applications and APIs to customer globally
  + CloudFront uses **AWS edge locations**
  + there are 100+ *edge locations* globally
  + CloudFront supports AWS endpoints
  + *CloudFront also supports non-AWS endpoints*
  + **expiring content**: you can force an expiration
- how does it work?
- settings?
  + CloudFront supports WAF
  + you can run a complete static website with your own SSL certificate on CloudFront

### Elasticache
- what is it?
  + Elasticache is an AWS managed version of open-source software: **memcached and redis**
  + **memcached** sits in front of a db and is a simple db caching solution
  + *memcached is not a db by itself*
  + no backups
  + **redis** is a caching solution that *can also function as a stand-alone NOSQL database*
  + redis can failover and also do multi-AZ
  + redis supports backups

### DAX: Dynamodb caching
  + DAX is an in-memory caching solution for DynamoDB
  + DAX can reduce DynamoDB times from milliseconds to microseconds

### Fixing IP Caching with Global Accelerator
- what is Global Accelerator
  + Global Accelerator is a networking service that sends your user's traffic through AWSs global network infrastructure
  + Global Accelerator is designed to increase peformance by dealing with the problem of IP caching
  + Global Accelerator uses AWS edge locations
- features
  + weighting: you can create different weighting options in each region your architecture lives in

### AWS caching exam tips:
1. can it be cached?
2. what kind of cache can be deployed to fit the solution?
3. how does the content in your cache get updated?  -TTL?
4. does caching add anything else besides speed?
- **CloudFront is the only option to add HTTP to a static website being hosted in an S3 bucket**
- Global Accelerator: two static IP address to solve problem of IP caching
- AWS loves caching, favor solutions that have some type of caching component
- CloudFront's major use-case is speed; delivers customer content faster by caching content closer to the user
- Elasticache can sit in front of RDS or it can be a stand-alone NOSQL db
- "in memory db":  Redis, DynamoDB
- you shouldnt use a cache as a *source of truth for your data*
  + **memecached and DAX are not a source of truth for your data**


## Managing AWS Accounts with Organizations
- what is "Organisations"?
  + AWS Organisations is a free governance tool that allows you to create and manage multiple AWS accounts
  + Organisations gives you a single pane of glass to control your accounts, instead of jumping from account to account
  + a **logging account** is a best practice
  + logging account is an account with some S3 buckets whose that aggrregate CloudTrail logs
  + Reserved Instances can be shared across account
  + billing consolidation ("main" account pays the bills for all associated accounts)
- what are **Service Control Policies**?
  + Service Control Policies (SCPs) enable cengtral administration over the permissions available within the accounts in your organisation
  + keeps account behaviours within your organization's access control guidelines
- exam tips
  + centralised logging solution: use Organisations and Service Control Policies to restrict anyone from making changes to them
  + Reserved Instances can be shared across accounts


### Sharing Resources with AWS Resource Access Manager
- what is RAM?
  + AWS Resource Access Manager is a free service that allows you to share AWS resources with **other accounts** within your **organisation**

- what can be shared? 
  + transit gateways
  + VPC subnets
  + license manager
  + R53 Resolver
- exam tips
  + if you are *sharing resources within the same region*, use RAM
  + if you are *sharing across regions*, use VPC peering

### Setting up X-Account Role Access
- why is x-account role access important? (use cases)
  + **duplicating IAM acccunts creates a security vulnerability**
  + x-accout role access gives you the ability to setup temporary access you can easily control
- how does x-account access get setup?
  + create a role
  + define permissions (attach policy)
  + grant access to the role
  + you then assign users from the second account the *permission to assume the role* in the first account

- exam tips
  + it is preferable to create x-account roles rather than additonal IAM credentials
  + **role assumption is temporary; you can't permanently assume a role**


### Inventory Management with AWS Config
- what is AWS Config?
  + AWS config is an *inventory management and control tool*
  + architecture discovery --query by resource type, tag
  + *you can see deleted infrastructure*

- exam tips
  +  **AWS Config is not a free serviice**
  + AWS Config can help you create and enforce standards across accounts
  + you can use **automation documents** or **Lambda** to enforce your standards

### Offloading Active Directory with Directory Service
- what is AWS Directory Service
  + AWS Directory Service is a fully managed AWS version of MS Active Directory

- exam tips
  + 2 types of Directory Service: **Managed MS AD** and **AD Connector**
  + if the customer wants to leave MS AD on Prem, AD Connector can bridge the gap between on prem and cloud resources needing directory and authentication services
  + whenever possible use Directory Service over EC2 instances for AD


### Exploring with Costs Explorer
- what is Cost Explorer?
  + AWS Cost Explorer allows you to visualize cloud costs
  + you can generate reports based on a variety of factors including resource tags
-  what can we do with  AWS Cost Explorer?
  + break down costs on a service-by-service basis
  + break down costs based on time periods -eg monthly, weekly
  + where is the spend coming from? --tags, categories etc

- exam tips
  + AWS Cost Explorer: **you have to set the tag as a cost allocation tag**
  + *Cost Explorer and Budgets go hand-in-hand*


### Using AWS Budgets
- What is AWS Budgets
  + allows organisations to easily **plan and set expectations around cloud costs**
- types of budgets
  + 4 Types of budgets (**you get two free every month!**)
  1. cost budgets
  2. usage budgets
  3. reservation budgets
  4. savings plan budgets

- exam tips
  + users can be alerted on *current spend* or *projected spend*
  + you can create a budget using tags as a filter

### Optimizing Costs with AWS Cost and Usage Reports
- what is AWS Cost and Usage Reports (CUR)?
  + AWS CUR is a comprehensive service that provies a comprehensive set of cost and usage data for your AWS spending
  + *publishes billing reports to Amazon S3 for centralised collection*
  + break down costs by time span --hour, day, month, as well as by *resource and tags*
  + *AWS CUR updates reports in S3 buckets once a day using CSV formats*
  + **integrations** Amazon Athena, Amazon Redshift, Amazon QuickSight
- use-cases
  + use within **AWS Organisations** for entire OU groups or individual member accounts
  + tracking savings plans
  + monitor on-Demand capcity reservations
  + break down your AWS data transfer charges (eg external vs inter-Region)
  + dive deeper int **cost allocation** tag resource spending

- exam tips
  + *AWS CUR is the most comprehensive and detailed view of your AWS spending*
  + centralised storage using S3
  + org leve, OU level, or simple account level

### Reducing Compute Spend Using Savings Plans and AWS Compute Optimizer
- what is the AWS Compute Optimizer
  + service that analyzes configurations and utilisation metrics of your AWS resources and helps you optimize them
  + it is a graphical service
  + supported resources: **ec2 , auto-scaling groups, ebs, lambda**
- AWS compute optimizer: supported accounts
  + standalone
  + member account
  + management account
- exam tips
  + **this service is disbabled by default!**
  + you must *opt-in* to leverage this service

- exam tips
  + AWS Compute Optimizer provides recommendations based on collected utilisation and configuration metrics


### Auditing with Trusted Advisor
- what is Trusted Advisor
  + AWS Trusted Advisor is a fully managed best-practice auditing tool
  + it will scan 5 different parts of your account and look for places where you could improve your adoption of AWS beset practices
- supported checks
  1. **cost optimization:**
  2. **performance:** are your services configured properly?
  3. **security:** is your AWS architecture full of vulnerabilties?
  4. **fault tolerance:** are you protected when something fails?
  5. **service limits:** do you have room to scale
- exam tips
  + Trusted Advisor can integrate with SNS for alerting and notification
  + **most of the usefule checks are locked behind a Business or an Enterprise support plan**
  + **Trusted Advisor will not remediate the problems** --it only alerts you that they exist
  + Lambda could potentially be used to automate some remediation activities
    + an EventBridge configuration could kick off a Lambda to fix a problem found by Trusted Advisor

### Enforcing Account Governance via AWS Control Tower
- What is AWS Control Tower?
  + AWS Control Tower is a way to setup and govern an AWS multi-account environment
  + combines with other AWS services (Organisations, IAM, Config etc) to become an *orchestration tool*

- exam tips
  + AWS Control Tower is an "account factory"

### Managing Software Licenses with AWS License Manager
- 

### Monitoring Health Events in the AWS Personal Health Dashboard
- what is the Personal Health Dashboard
  + new name: **AWS Health**
  + gives you additional visibility of resource performance and availability of AWS services or accounts
  + "near-instant" delivery of notifications and alerts
  + **you can automate actions based on incoming events using Amazon EventBridge**

### Standardizing Deployments Using AWS Service Catalog and AWS Proton
- what is AWS Service Catalog?
  + basically similar to a Terraform project for deploying sets of infrastructure
- benefits of using AWS Service catalog
- AWS Proton
  + a service that creates and manages infrastructure and deployment tooling for users as well as serverless and container-based applications
  + **AWS Proton supports Terraform**
- exam tips

### Optimizing Architectures with the AWS Well-Architected Tool
- six pillars
  + operational excellence
  + reliability
  + security
  + peformance efficiency
  + cost optimization
  + sustainability
- AWS well-architected tool *measures current workloads against established best practices*


### Governance exam tips
1. can it be centralised?
2. how do we standardize it?
3. how do we enforce standards that we want set
4. are the users "internal" or "external"?

- with **AWS Organisations**, *Service Control Policies have the ultimate say as to whether and API call can go thru--they are the only way to restrict what the root account can do*
- look for solutions that aggregate **centralised logs**
- **AWS Config**
  + automation documents
  + lambda
  + know what changed --but it is not a free service

- user access to API:   
  + AWS SSO for *internal users*
  + Cognito for *external users*
  + "Active Directory" solutions can sometimes be develped in AWS with AWS Directory, which is a *manageed MS AD in AWS*
    + "lift and shift" --use Amazon Directory
    + if AD is staying on prem --use AD Connector
  + favor x-account role access over multiple IAM credentials for different accounts

- **tracking costs**
  + tags, Cost Explorer, AWS Budgets
  + use AWS Compute Optimizer to generate recommendations on implementing more accurate compute sizes based on your actual needs
  + *detailed reports and exploring costs:* these questions will usually involve AWS Cost and Usage Reports (CUR) or Cost Explorer

- **AWS Trusted Advisor:**  free to use, but you will need a Business or Enterprise Support plan to get the most useful checks
  + Trusted Advisor *is strictlly an auditing tool* --it does not provide remediation
  + a common Trusted Advisor pattern is to use EventBridge to kick off a Lambda function to solve the problem for you

- **AWS Proton**
  + service platform to automate the provisioning of their entire application stack for container-based or serverless architectures


- **AWS Control Tower**
  + SCP --*preventive*
  + AWS Detective --*detective*

- **AWS Health** *formerly known as AWS Health Dashboard*
  + a dashboard and service meant to provide notifications of both public and private and account-specific events within AWS
  + any questions about service alerts or notifications of EC2 hardware maintenance reboots will leverage AWS Health in some manner


## Migrating Data with AWS Snow Family
- How do we migrate data?
- what is the Amazon Snow Family?
  + the Snow Family is a set of secure appliances that provide petabyte-scale data collection and processing solutions at the edge and migrate large-scale data into and out of aws
    + bascially it is a "mobile hard disk drive" service that Amazon ships to  your location
- Snowcone
  + smallest device
  + 8 TB storagge, 4GB mem, 2vCPUs
- Snowball Edge
  + 48TB+  storge
- SnowMobile
  + semi track
  + 100PB storage

### Amazon Storage Gateway
- Storage Gateway is hybrid cloud storage service that helps you merge on-premises resources with the cloud
- it can help with a one-time migration or long-term pairing of your architecture with AWS
- **File Gateway**
  + and NFS (or SMB) that you can mount locally in your on-premises network and it backs up your data into S3
  + it is essentially a VM provide by AWS
- **Volume Gateway** 
  + *Volume Gateway is an iSCSI mount* 
  + cached or stored mode
  + you can potentially convert your on-premise volumes to become EBS volumes
- **Tape Gateway**
  + directly integrates as an on-premise VM

- exam tips
  + storage gateway is a *hybrid solution*

### AWS DataSync Service
- what is DataSync?
  + AWS DataSync is an agent-based solution for migrating on-premise storage to AWS
  + Allows you to easily move data betweeen NFS and SMB shares and AWS storage solutions
- exam tips
  + DataSync vs Storage Gateway
    - DataSync is better-suited to a *one-time migration*

### AWS Transfer Family
- What is the AWS Transfer Family?
  + the AWS Transfer Family allows you to easily move files in and out of S3 or EFS using SFTP, FTPS or the File Transfer Protocol
  + the AWS Transfer Family excels when you have a collection of older applications that cannot be changed (FTPS, SFTP from outside the VPC in) (FTP within the VPC) 


### Moving the Cloud using Migration Hub
- What is AWS Migration Hub?
  + a single pane of glass for track the progress of your application migration to AWS
  + integrates with Server Migration Service (SMS) and Database Migration Service (DMS)
- **server migration service**
  + takes a copy of the Vshere volume and converts the VMs into an *ebs snaphot* and creates an AMI
- **database migration service**
  + can take an on-prem oracle database and run it thru the *AWS Schema Conversion Tool* and migrate it to an Aurora Database
  + AWS Database Migration service can also convert any MySQL DB into an Amazon Aurora DB instance


### Migrating Workloads to AWS Using AWS Application Discovery Service or AWS Application Migration Service
- What is the **AWS Application Discovery Service**?
  + a service that helps you plan migrations to the AWS cloud based on information collectiion on your on-premise network
  + track application migrations a groups in the AWS console
  + can be deployed with an *agentless discovery* performed via OVA in vCenter
- What is **AWS MGN**?
  + an automated "lift and shift" service for migrating on-premise apps to AWS
  + **RTO** Recovery Time Objective: typically measured in minutes
  + **RPO** Recovery Point Objective: measured in sub-second range

### AWS Database Migration Service
- What is the Database Migration Service?
  + a migration tool that allows for migration of data warehouses, NoSQL databases and other data stores to AWS
  + you can migrate to on-premise endpoints, *but at least one endpoint* must be in AWS
  + *DMS is a basically a server running replication software*
  + AWS creates the tables and the primary keys if they do not exist on the target
  + *the source and target data stores are known as endpoints*
- What is the AWS Schema Conversion Tool (SCT)?
  + convert existing database schema from one engine to another
  +  convert various types of relational databaase, including OLAP and OLTP
  + support for data warehouse
  + converted target schemas can be used for any supported amazon RDS engine type, or Amazon Aurora, or Amazon Redshift
  + you can use the converted schemas with databases running on EC2 or data stored in S3

#### 3 Different Migration Patterns with DMS
1. *Full load* all migration data is moved from sources to targets in parallel
2. *Full Load and Change Data Capture (CDC)* captures changes to source tables during migration
  + CDC gurantees *transactional integrity* of the target database
3. *CDC Only* only replicate the data changes from the source database

#### Migrating Large Data Stores via AWS Snowball
- TB capacity
- avoids bandwidth throttles
- use Snowball Edge devices with DMS to migrate large data sets quickly
- SCT: you can still leverage SCT to extract data into Snowball devcies and then into S3
- load converted data: DMS can still load the extracted data from S3 and migrate to the chosen destination
- CDC compatible: still be able to leverage CDC for capturing changes when extracting data to store in S3

- exam tips
  + runs a replication service software that executes specific tasks
  + CDC: Change Data Capture
  + one endpoint MUST be on AWS
  + SCT: **Schema Converstion Tool**
  + Snowball can be used with DMS

### Replicating and Tracking Migrations with the AWS Migration Hub and AWS Server Migration Service
- What is Migration Hub
  + a singular place to discover exisitng VMs, plan your migration effort, and track migration statuses
- phases
  + discovery
  + migration
  + tracking

- Server Migration Service (SMS)
  + incremental replications of your server VMs
  + multi-server migrations
  + group applications and track progress
  + multi-os support
  - minimizes downtime


### Data Migration Exam tips
- 4 questions
  1. where are we going?
  2. how do we get there?
  3. is it all at once?
  4. is it a *partial migration* to the cloud?

- Snowball choices are often based on how much data you're moving
  + good choice for slow/no Internet
  + use case for TBs of data

- Storage Gateway
  + File Gateway is a good choice if your local network-attached storage is full

- DataSync
  + good for one-time migration of file shares into AWS
  + EFS/FSx are both viable locations for DataSync to transfer content into

- Migration Hub
  + organizatonal tool
  + DOES NOT actually do the migration
  + AWS Schema Conversion Tool
  + **Server Migration Service** will help move VMs out of the data center and into AWS

- Application Discovery Service
- Application Migration Service
  + AWS MGN
  + "lift and shift" service for migrating infrastructure into AWS
  + Server Migration Service vs Application Migration Service?



## Front-End Web and Mobile
- what is AWS Amplify
  + AWS Amplify offers tools for front-end web and mobile developers
  + **you cannot do server-side rendering with a static application in S3**
- testing APP sevices using AWS Device Farm
  + 
- AWS Pinpoint
  + pinpoint enables you to engage with customers through a variety of different messaging channels

- exam tips
- Amplify is an AWS service for front-end web and mobile development
- **Amplify supports server-side rendering**

## Machine Learning
- Amazon Rekognition
  + Rekognition is Amazon's computer vision product that automates the recognition of pictures and videos using deep learning and neural networks
  + you can use these processes to understand and label what is in pictures and videos
  + common use-case: content moderation, celebrity recognition
  + uses AI and ML
- Amazon Comprehend,Kendra, Textract
  + Comprehend uses NLP to help you understand sentiment at scale
  + Kendra allows you to create an intelligent search service powered by ML
  + Textract uses ML to automatically extract text, handwriting, and data from scanned documents
- Amazon Forecast
  + time series data are data points that are logged over a series of time, allowing you to track your data
- Amazon Fraud Detector
  + AWS AI service used to detect fraud in your data
  + uses a ML model that gets trained on your data
- Polly, Transcribe, Lex
  + *Polly*: turns text into "lifelike" speach
  + *Transcribe*: convert speach to text automatically
  + *Lex*: uses natural language models to build converstational interfaces into your applications
- Amazon SageMaker to train learning  models
  + what is SageMaker?
    - SageMaker is a cloud machine-learing platform that enables developers to create, train, and deploy machine-learning models in the cloud
    - it also allows developers to deploy ML models on embedded systems and
    edge-devices
    - GroundTruth: setup and manage labelling jobs
    - Notebook: access a managed Jupyter Notebook environmen t
    - Training: train and tune your models
    - Inference: package and deploy your machine learning models at scale
  + deployment types?
    - offline usage: when immediate repsonse is not required
    - online usage: immediate response
  + SageMaker Stages
    - create a model
    - create an endpoint configuration
    - create an endpoint
  + Elastic Inference
    - EI sppeds up throughput and decreases latency of real-time inferences deployed on SageMaker hosted services using only CPU-based instances
    - GPU-based instances are higher-performing, but more expensive
  + Automatic Scaling
  + High Availability
    + with multi-AZ, if one AZ goes down, SageMaker will automatically provision your model in another AZ

- examp tips: Machine Learning
  + SageMaker is used to create machine learning models
  + Comprehend: text analysis that can be used for sentiment analysis
  + Kendra: builds an intelligent search service from unstructured text
  + Forecast: used for time-series data forecasting
  + fraud detection machine-learning model
  + Amazon Polly converts text into natural speech and talks back to you



## Media
- Converting Media Files with **Amazaon Elastic Transcoder**
  + what is Amazon Elastic Transcoder
  + Elastic Transcoder is a service to covert ("transcode") media files from their original source format into versions that are optimized for various devices, such as smartphones, tables and PCs
- Streaming Live video in AWS using AWS Kinesis Video Streams
  + What are Kinesis Video Streams?
  + streams media content from a large number of devices to AWS
  + allows subsequent *analytics* and *machine learning* tasks
  + use-case Amazon Ring, "smart cities" (CCTV), industrial automation
    - eg you can stream video content from your Ring devices to Kinesis Video Streams and then run analysis on the data
- exam tips
  + change video formats: Elastic Transcoder
  + Kinesis Video Streams: video streams at scale


## links
https://www.youtube.com/watch?v=g2JOHLHh4rI
https://blog.ashiny.cloud/page/awscli-query-quickref/
https://www.awsboy.com/aws-cheat-sheet-vpc/
https://tutorialsdojo.com/amazon-vpc/
https://pbxbook.com/other/cidrcheat.html
https://medium.com/circuitpeople/aws-cli-with-jq-and-bash-9d54e2eabaf1
https://www.bluematador.com/learn/aws-cli-cheatsheet
https://medium.com/@neonforge/the-ultimate-cheatsheet-for-aws-solutions-architect-exam-saa-c02-part-1-ed56a8096392
https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html
https://aws.amazon.com/whitepapers/?whitepapers-main.sort-by=item.additionalFields.sortDate&whitepapers-main.sort-order=desc&awsf.whitepapers-content-type=*all&awsf.whitepapers-global-methodology=*all&awsf.whitepapers-tech-category=*all&awsf.whitepapers-industries=*all&awsf.whitepapers-business-category=*all
https://www.wellarchitectedlabs.com/?ref=wellarchitected-wp
https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_billing.html
https://aws.amazon.com/ec2/instance-types/
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-discovery.html
https://dev.to/napicella/aws-networking-cheat-sheet-eip-eni-vpc-etc-139m
cidr.xyz
https://ns1.com/blog/the-difference-between-alias-and-cname


055737697065